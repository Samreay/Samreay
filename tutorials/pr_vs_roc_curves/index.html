<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>PR vs ROC Curves - Which to Use? - Samuel Hinton</title><link rel=stylesheet href="https://cosmiccoding.com.au/css/main.min.5885372f23ef07b79bc16e6f2da719ab7aef8e679a9f36a46a5dfe568f4d60e7.css" integrity="sha256-WIU3LyPvB7ebwW5vLacZq3rvjmeanzakal3+Vo9NYOc="><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel="shortcut icon" href=https://cosmiccoding.com.au/img/favicon.png type=image/x-icon></head><meta name=description content="Exploring the difference between the graphs using python."><meta name=robots content="noodp"><link rel=canonical href=https://cosmiccoding.com.au/tutorials/pr_vs_roc_curves/><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cosmiccoding.com.au/tutorials/pr_vs_roc_curves/cover.png"><meta name=twitter:title content="PR vs ROC Curves - Which to Use?"><meta name=twitter:description content="Exploring the difference between the graphs using python."><meta property="og:title" content="PR vs ROC Curves - Which to Use?"><meta property="og:description" content="Exploring the difference between the graphs using python."><meta property="og:type" content="article"><meta property="og:url" content="https://cosmiccoding.com.au/tutorials/pr_vs_roc_curves/"><meta property="og:image" content="https://cosmiccoding.com.au/tutorials/pr_vs_roc_curves/cover.png"><meta property="article:section" content="tutorials"><meta property="article:published_time" content="2020-07-15T00:00:00+00:00"><meta property="article:modified_time" content="2020-07-15T00:00:00+00:00"><meta property="article:section" content="tutorial"><meta property="article:published_time" content="2020-07-15 00:00:00 +0000 UTC"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"PR vs ROC Curves - Which to Use?","genre":"tutorial","url":"https:\/\/cosmiccoding.com.au\/tutorials\/pr_vs_roc_curves\/","datePublished":"2020-07-15 00:00:00 \u002b0000 UTC","description":"Exploring the difference between the graphs using python.","author":{"@type":"Person","name":""}}</script><body><div class="flex flex-col min-h-screen overflow-hidden"><header class="absolute w-full z-30"><div class="max-w-6xl mx-auto px-4 sm:px-6"><div class="flex items-center justify-between h-20"><div class="flex-shrink-0 mr-4"><a class=block href=/ aria-label="Samuel Hinton"><h2 class=logo>SRH</h2></a></div><nav class="hidden md:flex md:flex-grow"><ul class="flex flex-grow justify-end flex-wrap items-center"><li><a href=/#books class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Books</a></li><li><a href=/reviews class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Reviews</a></li><li><a href=/tutorials class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Tutorials</a></li><li><a href=/blogs class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Blog</a></li><li><a href=/#courses class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">CV</a></li></ul></nav><div class=md:hidden x-data="{ expanded: false }"><button class=hamburger :class="{ 'active': expanded }" @click.stop="expanded = !expanded" aria-controls=mobile-nav :aria-expanded=expanded>
<span class=sr-only>Menu</span><svg class="w-6 h-6 fill-current text-gray-300 hover:text-gray-200 transition duration-150 ease-in-out" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><rect y="4" width="24" height="2" rx="1"/><rect y="11" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg></button><nav id=mobile-nav class="absolute top-full z-20 left-0 w-full px-4 sm:px-6 overflow-hidden transition-all duration-300 ease-in-out" x-ref=mobileNav :style="expanded ? 'max-height: ' + $refs.mobileNav.scrollHeight + 'px; opacity: 1' : 'max-height: 0; opacity: .8'" @click.away="expanded = false" @keydown.escape.window="expanded = false" x-cloak><ul class="bg-gray-800 px-4 py-2"><li><a href=/#books class="flex text-gray-300 hover:text-gray-200 py-2">Books</a></li><li><a href=/reviews class="flex text-gray-300 hover:text-gray-200 py-2">Reviews</a></li><li><a href=/tutorials class="flex text-gray-300 hover:text-gray-200 py-2">Tutorials</a></li><li><a href=/blogs class="flex text-gray-300 hover:text-gray-200 py-2">Blog</a></li><li><a href=/#courses class="flex text-gray-300 hover:text-gray-200 py-2">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="flex text-gray-300 hover:text-gray-200 py-2">CV</a></li></ul></nav></div></div></div></header><div class=flex-grow><div id=post-container class="content content-wider blog-post relative"><div class="section-header blog"><h1 class=title>PR vs ROC Curves - Which to Use?</h1><p>6th July 2020</p><p>Exploring the difference between the graphs using python.</p></div><div><ul class="grid gap-6 w-full md:grid-cols-2" style=list-style:none;padding-left:0><li><input type=radio id=show-code name=code-toggle value=show-code class="hidden peer" onchange=clickCheckbox(this) required checked>
<label for=show-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Show me everything!</div><div class="w-full text-center text-sm">Oh yeah, coding time.</div></div></label></li><li><input type=radio id=hide-code name=code-toggle value=hide-code class="hidden peer" onchange=clickCheckbox(this)>
<label for=hide-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Just the plots</div><div class="w-full text-center text-sm">Code is nasty.</div></div></label></li></ul></div><script>function clickCheckbox(e){e.id=="show-code"?document.getElementById("post-container").classList.remove("hide-code"):document.getElementById("post-container").classList.add("hide-code")}</script><p>PR curves and ROC diagrams are presented everywhere in the machine learning sphere, and are often used relatively interchangably. In many cases, this is fine, because they are both providing information on the general question &ldquo;How good is my classifier?&rdquo;. But like many things which are often fine to do, there are cases where we&rsquo;d want to specifically show either a PR or ROC curve.</p><p>So in the next few sections, we&rsquo;ll generate a mock dataset, generate PR and ROC curves for them for two different classifiers, go into the definition of both of PR and ROC curves (both the intuition and mathematics), and then we&rsquo;ll go how they subtly differ with another code example.</p><h1 id=a-toy-example>A toy example</h1><p>Let&rsquo;s utilise the <code>make_moon</code> function from <code>sklearn</code> to get some toy data, and then super quickly train both a logistic regression and random forest classifier on it.</p><div class=width-77 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.datasets <span style=color:#ff6ac1>import</span> make_moons
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.model_selection <span style=color:#ff6ac1>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.ensemble <span style=color:#ff6ac1>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.linear_model <span style=color:#ff6ac1>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> precision_recall_curve
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Generate some mock data</span>
</span></span><span style=display:flex><span>X, y <span style=color:#ff6ac1>=</span> make_moons(n_samples<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>10000</span>, noise<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#ff6ac1>=</span> train_test_split(X, y, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Fit two basic models</span>
</span></span><span style=display:flex><span>models <span style=color:#ff6ac1>=</span> [RandomForestClassifier(), LogisticRegression()]
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> []
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    m<span style=color:#ff6ac1>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    results<span style=color:#ff6ac1>.</span>append(m<span style=color:#ff6ac1>.</span>predict(X_test))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Plot results</span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>+</span> <span style=color:#ff5c57>len</span>(models), sharey<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>scatter(X[:, <span style=color:#ff9f43>0</span>], X[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>y, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Spectral&#34;</span>)
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;Actual data&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> ax, m, r <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(axes[<span style=color:#ff9f43>1</span>:], models, results):
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>scatter(X_test[:, <span style=color:#ff9f43>0</span>], X_test[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>(r <span style=color:#ff6ac1>==</span> y_test), cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;RdYlGn&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;</span><span style=color:#5af78e>{</span>m<span style=color:#ff6ac1>.</span>__class__<span style=color:#ff6ac1>.</span>__name__<span style=color:#5af78e>}</span><span style=color:#5af78e>\n</span><span style=color:#5af78e>Correct classification&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_1_0_hu0ede8a6d26e9264d9d8a0b218ab2a7f6_1212506_4281x1907_resize_q90_h2_box_3.webp width=4281 height=1907 type=image/webp><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_1_0_hu0ede8a6d26e9264d9d8a0b218ab2a7f6_1212506_4281x1907_resize_q90_box_3.png width=4281 height=1907 type=image/png><img width=4281 height=1907 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>So here we have some simple moon data, two classifiers, one naively looks better than the other, we want to determine the threshold in which its internal &ldquo;probability&rdquo; results in us classifying into one group or another. Where we set that limit will determine, how much contamination is in the positives, vs positives we failed to get.</p><h1 id=what-is-a-pr-curve>What is a PR Curve?</h1><p>A <strong>Precision-Recall</strong> curve is exactly what it sounds like. It allows us to see the relationship between the <strong>precision</strong> (the number of true positives over the total number of positives - true positives and false positives combined) and the <strong>recall</strong> (number of true positives over the total number of real true values - the true positives and false negatives combined).</p><p>To rephrase:</p><ul><li>Precision is asking how many true successes are in all our reported successes</li><li>Recall is out of all the true values that went in, how many did we successfully get back out.</li></ul><p>Now there is obviously going to be an inverse relationship out. If we have increase our precision, that means we want to remove <strong>False Positives</strong> from our predictions, so we&rsquo;d throw out more events. But because some of the events we throw out might be true events, we would decrease our <strong>recall</strong>. So we want to hit a sweet spot, and where that is depends on your business case.</p><p>We can generate a PR curve easily in sklearn like so:</p><div class="reduced-code width-57" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> plot_precision_recall_curve
</span></span><span style=display:flex><span><span style=color:#78787e># Can do it manually by importing precision_recall_curve</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_precision_recall_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>ax)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axhline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axvline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;PR Curve&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_3_0_hu34461b7ca5e8eb425d7594465b0a737c_154073_2794x1599_resize_q90_h2_box_3.webp width=2794 height=1599 type=image/webp><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_3_0_hu34461b7ca5e8eb425d7594465b0a737c_154073_2794x1599_resize_q90_box_3.png width=2794 height=1599 type=image/png><img width=2794 height=1599 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>The &ldquo;AP&rdquo; in the plot is the average precision, weighted by the change in recall. <a href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html>See this link for details</a>. The important thing is to note the characteristic curve we see, and that what you want is for your curve to get as high up in the upper right corner as possible. Here, we can see that we could pick a classification threshold for the Random Forest Classifier that would grant us a precision of > 90% and still have a recall of also above 90% (the dashed lines are at the 90% mark, and you can see the curve gets aboe both of them).</p><h1 id=what-is-a-roc-curve>What is a ROC curve?</h1><p>A <strong>receiver operating characteristic curve</strong> (ROC curve) is similar to a PR curve. Instead of plotting precision vs recall, we plot the <strong>True Positive Rate</strong> against the <strong>False Positive Rate</strong>. The TPR is just another name for <strong>recall</strong> (its also called sensitivity). The FPR (also known as fallout, and 1 - TNR, aka 1 - specificity) is defined as the number false positivies over the total number of negatives (false positives plus true negatives).</p><p>To rephrase:</p><ul><li>TPR is recall: out of all the true values that went in, how many did we successfully get back out.</li><li>FPR is the chance we contaminate our sample with a false positive.</li></ul><p>We can generate a ROC curve easily using sklearn as well:</p><div class="reduced-code width-48" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> plot_roc_curve
</span></span><span style=display:flex><span><span style=color:#78787e># Can do it manually by importing roc_curve</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_roc_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>ax)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axhline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axvline(<span style=color:#ff9f43>0.1</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;ROC Curve&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_5_0_hu95fc04cd8a10bf32636218579f8d9466_158990_2794x1599_resize_q90_h2_box_3.webp width=2794 height=1599 type=image/webp><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_5_0_hu95fc04cd8a10bf32636218579f8d9466_158990_2794x1599_resize_q90_box_3.png width=2794 height=1599 type=image/png><img width=2794 height=1599 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>In this plot, we want to get in the top left corner, not the top right one. The dashed lines show us that our current RF model can achieve a true positive rate of >90%, with a false positive rate of &lt;10%.</p><p>And all things considered, it looks very similar to the PR curve, just flipped around. But there is an important difference that isn&rsquo;t just semantics.</p><h1 id=examining-the-difference>Examining the difference</h1><p>Let&rsquo;s make this a little more formal, and take a step back to the three things we care about that make up these two plots. Let us quickly denote $Y$ the <em>true</em> label, and $\hat{Y}$ our predicted label. The hat operator is often used as our &ldquo;observation&rdquo; or estimate, and we would write &ldquo;the probability of $x$ given $y$&rdquo; as $P(x|y)$.</p><ul><li><strong>Precision</strong>: How many true successes are in all of our labeled successes. $P(Y=1|\hat{Y}=1)$.</li><li><strong>Recall/TPR</strong>: Out of all the true values that went in, how many came out. $P(\hat{Y}=1|Y=1)$.</li><li><strong>FPR</strong>: The chance we contaminate our sample with a false positive. $P(\hat{Y}=1|Y=0)$.</li></ul><p>The important difference to note is that for the ROC curve, (TPR and FPR), the actual truth values are on the right hand side (they are conditioned on). For the PR curve, the precision has the predicted label on the right hand side. So one term is conditioned on the truth, the other on the estimate.</p><p>When will this make a difference?</p><p>When the classes are imbalanced, or you care more about getting a true positive than a false negative. Imagine the difference between a recommendor system that might not recommend you a movie you actually would have liked (no big deal), and medical imaging algorithm that failes to detect cancer when its present in the image (a very big deal).</p><p>Imagine if we look at a dataset with 100 cases in it. Either movies you want to watch, or people with cancer. And there are 100000 negatives (bad movies, healthy patients). Two classifiers, A and B, are run, and both get 99 out of the 100 cases correct; their recall is the same. But classifier A predicts 150 outcomes in total (99 true positives, 51 false positives), and classifier B predicts 1000 cases (99 true positives, 901 false positives). Their precision and FPR is different.</p><ul><li><strong>Classifier A</strong>: Recall=0.99, Precision=99/150=0.66, FPR=51/(51+100000)=0.0005</li><li><strong>Classifier B</strong>: Recall=0.99, Precision=99/1000=0.099, FPR=901/(901+100000)=0.008</li></ul><p>By looking at the ROC curve (Recall and FPR), the two classifiers look like they have similarly great performance! Same recall, and the FPR is absolutely tiny! But if we look at the PR curve (Recall and Precision), they look totally difference - one has a precision of 0.66, the other &lt;0.1!</p><p>With these sort of imbalanced class numbers, we can see why we might prefer PR curves in these cases.</p><p>In fact, lets quickly update the code above to produce an imbalanced set, and run two different classifiers, so we can compare the curves:</p><div class=width-75 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># Generate some mock data</span>
</span></span><span style=display:flex><span>X, y <span style=color:#ff6ac1>=</span> make_moons(n_samples<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>10000</span>, <span style=color:#ff9f43>500</span>), noise<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.2</span>, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#ff6ac1>=</span> train_test_split(X, y, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Fit some basic random forest</span>
</span></span><span style=display:flex><span>models <span style=color:#ff6ac1>=</span> [RandomForestClassifier(), LogisticRegression()]
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> []
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    m<span style=color:#ff6ac1>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    results<span style=color:#ff6ac1>.</span>append(m<span style=color:#ff6ac1>.</span>predict(X_test))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#78787e># Plot results</span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff5c57>len</span>(models)<span style=color:#ff6ac1>+</span><span style=color:#ff9f43>1</span>, sharey<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>scatter(X[:, <span style=color:#ff9f43>0</span>], X[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>y, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Spectral&#34;</span>)
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;Actual data&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> ax, m, r <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(axes[<span style=color:#ff9f43>1</span>:], models, results):
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>scatter(X_test[:, <span style=color:#ff9f43>0</span>], X_test[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>(r <span style=color:#ff6ac1>==</span> y_test), cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;RdYlGn&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;</span><span style=color:#5af78e>{</span>m<span style=color:#ff6ac1>.</span>__class__<span style=color:#ff6ac1>.</span>__name__<span style=color:#5af78e>}</span><span style=color:#5af78e>\n</span><span style=color:#5af78e>Correct Classification&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_7_0_huaf64add7a3208f49db8c382887961503_839881_4281x1907_resize_q90_h2_box_3.webp width=4281 height=1907 type=image/webp><source srcset=/tutorials/pr_vs_roc_curves/2020-07-15-PR_vs_ROC_Curves_files/2020-07-15-PR_vs_ROC_Curves_7_0_huaf64add7a3208f49db8c382887961503_839881_4281x1907_resize_q90_box_3.png width=4281 height=1907 type=image/png><img width=4281 height=1907 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>In this example, the classes are imbalanced by a factor of 20, so lets see if the imbalanced classes cause a large discrepancy now in the PR curve than in the ROC curve:</p><div class=width-62 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>2</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>12</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_precision_recall_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>axes[<span style=color:#ff9f43>0</span>])
</span></span><span style=display:flex><span>    plot_roc_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>axes[<span style=color:#ff9f43>1</span>])
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;PR Curve&#34;</span>), axes[<span style=color:#ff9f43>1</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;ROC Curve&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class="img-main rounded"><picture><source srcset=/tutorials/pr_vs_roc_curves/cover_hue0749b0e801c40e62c217686a2f612bc_232454_4048x1901_resize_q90_h2_box_3.webp width=4048 height=1901 type=image/webp><source srcset=/tutorials/pr_vs_roc_curves/cover_hue0749b0e801c40e62c217686a2f612bc_232454_4048x1901_resize_q90_box_3.png width=4048 height=1901 type=image/png><img width=4048 height=1901 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Fantastic, just as we expect. The ROC shows that, in general, the Random Forest performs better than the Logistic Regression (if, of course, we choose to use the TPR and FPR to measure performance). And the PR curve takes our specific class imbalance into account and shows the larger difference between in performance between the two classifiers due to the large difference in precision between them.</p><h1 id=summary>Summary</h1><p>In general, the ROC curve answers the question of how well the model performs with no knowledge of the class imbalance, whilst the PR curve uses our estimated class imbalance baseline to inform us of how well our model performs, given the specific imbalance we provided it.</p><p>For more reading on this topic, I recommend the following resources and threads, many of which inspire the explanations above:</p><ul><li><a href=https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/>Machine Learning Mastery - Jason Brownlee</a></li><li><a href=https://towardsdatascience.com/on-roc-and-precision-recall-curves-c23e9b63820c>Towards Data Science - Carlos Azevedo</a></li><li><a href=https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves>Stats Stack Exchange - numerous</a></li></ul><p>I hope this page and the resources above are useful!</p><hr><p>For your convenience, here&rsquo;s the code in one block:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.datasets <span style=color:#ff6ac1>import</span> make_moons
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.model_selection <span style=color:#ff6ac1>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.ensemble <span style=color:#ff6ac1>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.linear_model <span style=color:#ff6ac1>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> precision_recall_curve
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Generate some mock data</span>
</span></span><span style=display:flex><span>X, y <span style=color:#ff6ac1>=</span> make_moons(n_samples<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>10000</span>, noise<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#ff6ac1>=</span> train_test_split(X, y, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Fit two basic models</span>
</span></span><span style=display:flex><span>models <span style=color:#ff6ac1>=</span> [RandomForestClassifier(), LogisticRegression()]
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> []
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    m<span style=color:#ff6ac1>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    results<span style=color:#ff6ac1>.</span>append(m<span style=color:#ff6ac1>.</span>predict(X_test))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Plot results</span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>+</span> <span style=color:#ff5c57>len</span>(models), sharey<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>scatter(X[:, <span style=color:#ff9f43>0</span>], X[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>y, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Spectral&#34;</span>)
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;Actual data&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> ax, m, r <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(axes[<span style=color:#ff9f43>1</span>:], models, results):
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>scatter(X_test[:, <span style=color:#ff9f43>0</span>], X_test[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>(r <span style=color:#ff6ac1>==</span> y_test), cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;RdYlGn&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;</span><span style=color:#5af78e>{</span>m<span style=color:#ff6ac1>.</span>__class__<span style=color:#ff6ac1>.</span>__name__<span style=color:#5af78e>}</span><span style=color:#5af78e>\n</span><span style=color:#5af78e>Correct classification&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> plot_precision_recall_curve
</span></span><span style=display:flex><span><span style=color:#78787e># Can do it manually by importing precision_recall_curve</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_precision_recall_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>ax)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axhline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axvline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;PR Curve&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> sklearn.metrics <span style=color:#ff6ac1>import</span> plot_roc_curve
</span></span><span style=display:flex><span><span style=color:#78787e># Can do it manually by importing roc_curve</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_roc_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>ax)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axhline(<span style=color:#ff9f43>0.9</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>axvline(<span style=color:#ff9f43>0.1</span>, c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#39;w&#39;</span>, ls<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;--&#34;</span>, lw<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.5</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;ROC Curve&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#78787e># Generate some mock data</span>
</span></span><span style=display:flex><span>X, y <span style=color:#ff6ac1>=</span> make_moons(n_samples<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>10000</span>, <span style=color:#ff9f43>500</span>), noise<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.2</span>, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#ff6ac1>=</span> train_test_split(X, y, random_state<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Fit some basic random forest</span>
</span></span><span style=display:flex><span>models <span style=color:#ff6ac1>=</span> [RandomForestClassifier(), LogisticRegression()]
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> []
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    m<span style=color:#ff6ac1>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    results<span style=color:#ff6ac1>.</span>append(m<span style=color:#ff6ac1>.</span>predict(X_test))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#78787e># Plot results</span>
</span></span><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff5c57>len</span>(models)<span style=color:#ff6ac1>+</span><span style=color:#ff9f43>1</span>, sharey<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>scatter(X[:, <span style=color:#ff9f43>0</span>], X[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>y, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Spectral&#34;</span>)
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;Actual data&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> ax, m, r <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(axes[<span style=color:#ff9f43>1</span>:], models, results):
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>scatter(X_test[:, <span style=color:#ff9f43>0</span>], X_test[:, <span style=color:#ff9f43>1</span>], c<span style=color:#ff6ac1>=</span>(r <span style=color:#ff6ac1>==</span> y_test), cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;RdYlGn&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;</span><span style=color:#5af78e>{</span>m<span style=color:#ff6ac1>.</span>__class__<span style=color:#ff6ac1>.</span>__name__<span style=color:#5af78e>}</span><span style=color:#5af78e>\n</span><span style=color:#5af78e>Correct Classification&#34;</span>);
</span></span><span style=display:flex><span>fig, axes <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(ncols<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>2</span>, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>12</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> m <span style=color:#ff6ac1>in</span> models:
</span></span><span style=display:flex><span>    plot_precision_recall_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>axes[<span style=color:#ff9f43>0</span>])
</span></span><span style=display:flex><span>    plot_roc_curve(m, X_test, y_test, ax<span style=color:#ff6ac1>=</span>axes[<span style=color:#ff9f43>1</span>])
</span></span><span style=display:flex><span>axes[<span style=color:#ff9f43>0</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;PR Curve&#34;</span>), axes[<span style=color:#ff9f43>1</span>]<span style=color:#ff6ac1>.</span>set_title(<span style=color:#5af78e>&#34;ROC Curve&#34;</span>);
</span></span></code></pre></div><div class="relative max-w-xl mx-auto my-20"><div class="fancy_card horizontal"><div class=card_translator><div class="card_rotator tiny_rot card_layer"><div class="card_layer newsletter p-2"><div class="newsletter-inner h-full"><div class="relative h-full sib-form-container" id=sib-form-container><div class="mb-6 lg:mb-12 text-center"><h3 class="text-main-200 mb-2 lg:mb-8">Stay in the loop!</h3><p class="text-main-100 text-lg text-opacity-70">For new releases, exclusive giveaways, and reviews.</p></div><form action="https://Cosmiccoding.us5.list-manage.com/subscribe/post?u=aebe5de1d2e40dccb3aeca491&id=3987dd4a1f" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate w-full" target=_blank novalidate><div><input type=email class="w-full appearance-none bg-main-600 mb-4 border border-main-600 bg-opacity-5 focus:border-main-300 rounded-sm px-4 py-3 text-main-100 placeholder-main-100 required" placeholder="Your best email…" aria-label="Your best email…" name=EMAIL required data-required=true id=EMAIL><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_aebe5de1d2e40dccb3aeca491_3987dd4a1f tabindex=-1></div><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class="button btn bg-main-600 hover:bg-main-400 shadow w-full"></div><p id=mce-error-response style=display:none class="text-center mt-2 opacity-50 text-main-200">There was a problem, please try again.</p><p id=mce-success-response style=display:none class="text-center mt-2 opacity-50 text-main-200">Thanks mate, won't let ya down.</p></form></div></div></div><div class="card_layer card_effect card_soft_glare" style=pointer-events:none></div></div></div></div></div></div><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div><script language=javascript type=text/javascript src=https://cosmiccoding.com.au/js/main.min.11673d10a962fb5205229607e62ea1d23424d35dad33db7bfe2a09a63d5409fa.js></script>
<script async defer src="https://www.googletagmanager.com/gtag/js?id=UA-72691106-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-72691106-1")</script></div></body></html>