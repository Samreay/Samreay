<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Forward Modelling for Supernova Cosmology - Samuel Hinton</title><link rel=stylesheet href="https://cosmiccoding.com.au/css/main.min.b842bc4f8d358708f7b5666fe7108ed6474cd18dad036996cd6f85d3bb7b6a42.css" integrity="sha256-uEK8T401hwj3tWZv5xCO1kdM0Y2tA2mWzW+F07t7akI="><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel="shortcut icon" href=https://cosmiccoding.com.au/img/favicon.png type=image/x-icon></head><meta name=description content="A toy model implementation"><meta name=robots content="noodp"><link rel=canonical href=https://cosmiccoding.com.au/tutorials/forwardmodelling/><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cosmiccoding.com.au/tutorials/forwardmodelling/cover.png"><meta name=twitter:title content="Forward Modelling for Supernova Cosmology"><meta name=twitter:description content="A toy model implementation"><meta property="og:title" content="Forward Modelling for Supernova Cosmology"><meta property="og:description" content="A toy model implementation"><meta property="og:type" content="article"><meta property="og:url" content="https://cosmiccoding.com.au/tutorials/forwardmodelling/"><meta property="og:image" content="https://cosmiccoding.com.au/tutorials/forwardmodelling/cover.png"><meta property="article:section" content="tutorials"><meta property="article:published_time" content="2020-04-08T00:00:00+00:00"><meta property="article:modified_time" content="2020-04-08T00:00:00+00:00"><meta property="article:section" content="tutorial"><meta property="article:published_time" content="2020-04-08 00:00:00 +0000 UTC"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Forward Modelling for Supernova Cosmology","genre":"tutorial","url":"https:\/\/cosmiccoding.com.au\/tutorials\/forwardmodelling\/","datePublished":"2020-04-08 00:00:00 \u002b0000 UTC","description":"A toy model implementation","author":{"@type":"Person","name":""}}</script><body><div class="flex flex-col min-h-screen overflow-hidden"><header class="absolute w-full z-30"><div class="max-w-6xl mx-auto px-4 sm:px-6"><div class="flex items-center justify-between h-20"><div class="flex-shrink-0 mr-4"><a class=block href=/ aria-label="Samuel Hinton"><h2 class=logo>SRH</h2></a></div><nav class="hidden md:flex md:flex-grow"><ul class="flex flex-grow justify-end flex-wrap items-center"><li><a href=/#books class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Books</a></li><li><a href=/reviews class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Reviews</a></li><li><a href=/tutorials class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Tutorials</a></li><li><a href=/blogs class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Blog</a></li><li><a href=/#courses class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">CV</a></li></ul></nav><div class=md:hidden x-data="{ expanded: false }"><button class=hamburger :class="{ 'active': expanded }" @click.stop="expanded = !expanded" aria-controls=mobile-nav :aria-expanded=expanded>
<span class=sr-only>Menu</span><svg class="w-6 h-6 fill-current text-gray-300 hover:text-gray-200 transition duration-150 ease-in-out" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><rect y="4" width="24" height="2" rx="1"/><rect y="11" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg></button><nav id=mobile-nav class="absolute top-full z-20 left-0 w-full px-4 sm:px-6 overflow-hidden transition-all duration-300 ease-in-out" x-ref=mobileNav :style="expanded ? 'max-height: ' + $refs.mobileNav.scrollHeight + 'px; opacity: 1' : 'max-height: 0; opacity: .8'" @click.away="expanded = false" @keydown.escape.window="expanded = false" x-cloak><ul class="bg-gray-800 px-4 py-2"><li><a href=/#books class="flex text-gray-300 hover:text-gray-200 py-2">Books</a></li><li><a href=/reviews class="flex text-gray-300 hover:text-gray-200 py-2">Reviews</a></li><li><a href=/tutorials class="flex text-gray-300 hover:text-gray-200 py-2">Tutorials</a></li><li><a href=/blogs class="flex text-gray-300 hover:text-gray-200 py-2">Blog</a></li><li><a href=/#courses class="flex text-gray-300 hover:text-gray-200 py-2">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="flex text-gray-300 hover:text-gray-200 py-2">CV</a></li></ul></nav></div></div></div></header><div class=flex-grow><div id=post-container class="content content-wider blog-post relative"><div class="section-header blog"><h1 class=title>Forward Modelling for Supernova Cosmology</h1><p>6th April 2020</p><p>A toy model implementation</p></div><div><ul class="grid gap-6 w-full md:grid-cols-2" style=list-style:none;padding-left:0><li><input type=radio id=show-code name=code-toggle value=show-code class="hidden peer" onchange=clickCheckbox(this) required checked>
<label for=show-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Show me everything!</div><div class="w-full text-center text-sm">Oh yeah, coding time.</div></div></label></li><li><input type=radio id=hide-code name=code-toggle value=hide-code class="hidden peer" onchange=clickCheckbox(this)>
<label for=hide-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Just the plots</div><div class="w-full text-center text-sm">Code is nasty.</div></div></label></li></ul></div><script>function clickCheckbox(e){e.id=="show-code"?document.getElementById("post-container").classList.remove("hide-code"):document.getElementById("post-container").classList.add("hide-code")}</script><p>So in this example, I&rsquo;m simply trying to demonstrate the viability of forward models with supernova cosmology. In this, I&rsquo;ll be simplifying a lot, and in this case, ignoring proper treatment of uncertainty contributions from Monte-Carlo uncertainty. We&rsquo;ll start with a simple model in which simulated supernova have redshift, magnitude and colour, apply selection effects, and ensure that we can recover input cosmology without having to resimulate by exploiting the fact that our selection effects operate in the observer frame of reference.</p><h2 id=generating-data>Generating Data</h2><p>First things first - lets generate some random data in a horrifically simplified toy model.</p><div class=width-68 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> norm, uniform
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> astropy.cosmology <span style=color:#ff6ac1>import</span> FlatLambdaCDM
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> binned_statistic
</span></span><span style=display:flex><span>np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>seed(<span style=color:#ff9f43>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_fake_dist</span>(loc<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, size<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; To make sure we dont need a suite of tests, 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    fake sampling a normal so that it is symmetric&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    cdfs <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>cdf(norm<span style=color:#ff6ac1>.</span>rvs(size<span style=color:#ff6ac1>=</span>size))
</span></span><span style=display:flex><span>    maxv <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>min</span>(cdfs<span style=color:#ff6ac1>.</span>max(), <span style=color:#ff9f43>0.999</span>)
</span></span><span style=display:flex><span>    vals <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>ppf(np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> maxv, maxv, size)) <span style=color:#ff6ac1>*</span> scale <span style=color:#ff6ac1>+</span> loc
</span></span><span style=display:flex><span>    np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>shuffle(vals)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> vals
</span></span></code></pre></div></div><p>With a fake distance defined, we can plug that into generating fake data points.</p><div class="expanded-code width-83" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_events</span>(om<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, MB<span style=color:#ff6ac1>=-</span><span style=color:#ff9f43>19.3</span>, sigma_int<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, mean_c<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, 
</span></span><span style=display:flex><span>               sigma_c<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, beta<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>3.1</span>, num<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5000</span>):
</span></span><span style=display:flex><span>    zs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>1.05</span>, num)   
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#78787e># I sample bit by bit in redshift space to make sure our posterior </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># should be centered roughly on the true value, otherwise we&#39;d have </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># to run a suite of realisations to test the statistics rigorously.</span>
</span></span><span style=display:flex><span>    bins <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>100</span>
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>int</span>(num <span style=color:#ff6ac1>/</span> bins)
</span></span><span style=display:flex><span>    deltas <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([])
</span></span><span style=display:flex><span>    cs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([])
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> i <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>range</span>(bins):
</span></span><span style=display:flex><span>        deltas <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>concatenate((deltas, get_fake_dist(scale<span style=color:#ff6ac1>=</span>sigma_int, size<span style=color:#ff6ac1>=</span>n)))
</span></span><span style=display:flex><span>        cs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>concatenate((cs, get_fake_dist(loc<span style=color:#ff6ac1>=</span>mean_c, scale<span style=color:#ff6ac1>=</span>sigma_c, size<span style=color:#ff6ac1>=</span>n)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    MBs <span style=color:#ff6ac1>=</span> MB <span style=color:#ff6ac1>+</span> deltas <span style=color:#ff6ac1>+</span> beta <span style=color:#ff6ac1>*</span> cs
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, om)<span style=color:#ff6ac1>.</span>distmod(zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    mb <span style=color:#ff6ac1>=</span> distmod <span style=color:#ff6ac1>+</span> MBs
</span></span><span style=display:flex><span>    <span style=color:#78787e># Emulate some probabilistic selection effect</span>
</span></span><span style=display:flex><span>    mask <span style=color:#ff6ac1>=</span> (mb <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>rvs(scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, size<span style=color:#ff6ac1>=</span>num)) <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>24</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> mb[mask], zs[mask], cs[mask]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_mbs, data_zs, data_cs <span style=color:#ff6ac1>=</span> get_events()
</span></span></code></pre></div></div><p>Now, let&rsquo;s plot our generated data to make sure it all looks good.</p><div class="expanded-code width-82" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>3</span>))
</span></span><span style=display:flex><span>h <span style=color:#ff6ac1>=</span> ax<span style=color:#ff6ac1>.</span>scatter(data_zs, data_mbs, c<span style=color:#ff6ac1>=</span>data_cs, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;coolwarm&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>colorbar(h)<span style=color:#ff6ac1>.</span>set_label(<span style=color:#5af78e>&#34;colour&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_xlabel(<span style=color:#5af78e>&#34;$z$&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_ylabel(<span style=color:#5af78e>&#34;$m_B$&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class="img-main rounded"><picture><source srcset=/tutorials/forwardmodelling/cover_hud987045dbf814053a7a1990f606bb139_346214_1920x0_resize_q90_h2_box_3.webp width=1920 height=841 type=image/webp><source srcset=/tutorials/forwardmodelling/cover_hud987045dbf814053a7a1990f606bb139_346214_1920x0_resize_q90_box_3.png width=1920 height=841 type=image/png><img width=2722 height=1193 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Great, so we have &ldquo;data&rdquo;. If we want to fit it using some importance-sampling ABC method we need to:</p><ol><li>Create a base simulation</li><li>Reweight the simulation base on top-level parameters like Om, MB, sigma_int.</li><li>Compare the data to the re-weighted simulation to get a likelihood.</li></ol><div class="reduced-code width-54" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_sim_events</span>(num<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>100000</span>):
</span></span><span style=display:flex><span>    MBs <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>21.3</span>, <span style=color:#ff9f43>4</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    cs <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>1</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    betas <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff9f43>2</span>, <span style=color:#ff9f43>4.5</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    zs <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.05</span> <span style=color:#ff6ac1>+</span> uniform<span style=color:#ff6ac1>.</span>rvs(size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    <span style=color:#78787e># The value here for om doesnt actually matter</span>
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, <span style=color:#ff9f43>0.3</span>)<span style=color:#ff6ac1>.</span>distmod(zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    mb <span style=color:#ff6ac1>=</span> distmod <span style=color:#ff6ac1>+</span> MBs <span style=color:#ff6ac1>+</span> betas <span style=color:#ff6ac1>*</span> cs
</span></span><span style=display:flex><span>    <span style=color:#78787e># Emulate some probabilistic selection effect</span>
</span></span><span style=display:flex><span>    mask <span style=color:#ff6ac1>=</span> (mb <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>rvs(scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, size<span style=color:#ff6ac1>=</span>num)) <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>24</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> mb[mask], zs[mask], betas[mask], cs[mask]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sim_mbs, sim_zs, sim_betas, sim_cs <span style=color:#ff6ac1>=</span> get_sim_events()
</span></span></code></pre></div></div><p>Lets check the spread of this broad simulation.</p><div class="reduced-code width-45" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>3</span>))
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>hist2d(sim_zs, sim_mbs, bins<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>50</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_xlabel(<span style=color:#5af78e>&#34;$z$&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_ylabel(<span style=color:#5af78e>&#34;$m_B$&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_11_0_hu6ad3f26b29363c42c70cdbf49c40f9a1_45780_1920x0_resize_q90_h2_box_3.webp width=1920 height=809 type=image/webp><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_11_0_hu6ad3f26b29363c42c70cdbf49c40f9a1_45780_1920x0_resize_q90_box_3.png width=1920 height=809 type=image/png><img width=2832 height=1193 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Hopefully, its broad enough. Now to reweight the simulation based on the top-level parameters.</p><div class="expanded-code width-88" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>reweight</span>(sim_mbs, sim_zs, sim_cs, om, MB, sigma_int, mean_c, sigma_c, beta):
</span></span><span style=display:flex><span>    <span style=color:#78787e># Step 1: Use om to move from observer frame to rest frame</span>
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, om)<span style=color:#ff6ac1>.</span>distmod(sim_zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    sim_MBs <span style=color:#ff6ac1>=</span> sim_mbs <span style=color:#ff6ac1>-</span> distmod <span style=color:#ff6ac1>-</span> beta <span style=color:#ff6ac1>*</span> sim_cs
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#78787e># Use top-level parameters to get pdf of simulation points</span>
</span></span><span style=display:flex><span>    weights <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>logpdf(sim_MBs, MB, sigma_int) <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>logpdf(sim_cs, mean_c, sigma_c)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> np<span style=color:#ff6ac1>.</span>exp(weights)
</span></span></code></pre></div></div><p>Right, so we&rsquo;ve got this, but it would be good if we could actually do some MCMC on this bad boy. Let&rsquo;s make a likelihood function. For simplicity in this notebook I&rsquo;m going to break scope.</p><div class="reduced-code width-48" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># Define some histogram edges</span>
</span></span><span style=display:flex><span>mb_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>26</span>, <span style=color:#ff9f43>31</span>)
</span></span><span style=display:flex><span>z_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>1.05</span>, <span style=color:#ff9f43>31</span>)
</span></span><span style=display:flex><span>c_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>11</span>)
</span></span><span style=display:flex><span>mbc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (mb_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> mb_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>zc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (z_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> z_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>cc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (c_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> c_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>bins <span style=color:#ff6ac1>=</span> [mb_edges, z_edges, c_edges]
</span></span><span style=display:flex><span>data <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((data_mbs, data_zs, data_cs))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(data<span style=color:#ff6ac1>.</span>shape)
</span></span></code></pre></div></div><pre><code>(3476, 3)
</code></pre><p>So 3476 supernova in our little &ldquo;data&rdquo; sample, for each event we have the apparent magnitude, redshift and colour. Lets now bin these up.</p><div class=width-76 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>thresh <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>2</span>  <span style=color:#78787e># If you dont have more than 2 samples, dont count it</span>
</span></span><span style=display:flex><span>hist, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(data, bins<span style=color:#ff6ac1>=</span>[mb_edges, z_edges, c_edges])
</span></span><span style=display:flex><span>delta_vol <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>diff(mb_edges)[<span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>*</span> np<span style=color:#ff6ac1>.</span>diff(z_edges)[<span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>*</span> np<span style=color:#ff6ac1>.</span>diff(c_edges)[<span style=color:#ff9f43>0</span>]
</span></span><span style=display:flex><span>volume <span style=color:#ff6ac1>=</span> hist<span style=color:#ff6ac1>.</span>sum() <span style=color:#ff6ac1>*</span> delta_vol
</span></span><span style=display:flex><span>hist_err <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(hist)
</span></span><span style=display:flex><span>hist_err[hist_err <span style=color:#ff6ac1>&lt;</span> thresh] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>hist_err <span style=color:#ff6ac1>=</span> hist_err <span style=color:#ff6ac1>/</span> volume
</span></span><span style=display:flex><span>hist <span style=color:#ff6ac1>=</span> hist <span style=color:#ff6ac1>/</span> volume
</span></span></code></pre></div></div><p>And after binning the data, we need to now bin the simulations on the same grid.</p><div class=width-69 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sim <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((sim_mbs, sim_zs, sim_cs))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span>sim_count, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(sim, bins<span style=color:#ff6ac1>=</span>[mb_edges, z_edges, c_edges])
</span></span><span style=display:flex><span>sim_num_err <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(sim_count)
</span></span><span style=display:flex><span>sim_num_err[sim_num_err <span style=color:#ff6ac1>&lt;</span> thresh] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>sim_err_ratio <span style=color:#ff6ac1>=</span> sim_num_err <span style=color:#ff6ac1>/</span> sim_count
</span></span><span style=display:flex><span>sim_err_ratio[sim_count <span style=color:#ff6ac1>==</span> <span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span></code></pre></div></div><p>And we&rsquo;ll now add in functions to compute the $\chi^2$ value, and the log posterior as well (I&rsquo;m nastily just hacking in parameter bounds that are just flat priors).</p><div class="expanded-code width-95" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_chi2</span>(x, plot<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>):
</span></span><span style=display:flex><span>    om, MB, sigma_int, mean_c, sigma_c, beta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#78787e># Add a prior onto MB to help fitting</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    weights <span style=color:#ff6ac1>=</span> reweight(sim_mbs, sim_zs, sim_cs, om, MB, sigma_int, mean_c, sigma_c, beta)
</span></span><span style=display:flex><span>    <span style=color:#78787e># Now need a likelihood combining data and simulation. This is super simple, we&#39;d probably </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># want something like 1712.01293 in a real analysis where we combine MC and Poisson uncert.</span>
</span></span><span style=display:flex><span>    sim_hist, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(sim, bins<span style=color:#ff6ac1>=</span>bins, weights<span style=color:#ff6ac1>=</span>weights, density<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>)
</span></span><span style=display:flex><span>    sim_err <span style=color:#ff6ac1>=</span> sim_hist <span style=color:#ff6ac1>*</span> sim_err_ratio
</span></span><span style=display:flex><span>    chi2 <span style=color:#ff6ac1>=</span> ((sim_hist <span style=color:#ff6ac1>-</span> hist)<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>/</span> (hist_err<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> sim_err<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>))
</span></span><span style=display:flex><span>    chi2 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>nan_to_num(chi2, copy<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>)<span style=color:#ff6ac1>.</span>sum()
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> chi2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_log_posterior</span>(x):
</span></span><span style=display:flex><span>    om, MB, sigma_int, mean_c, sigma_c, beta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    bounds <span style=color:#ff6ac1>=</span> [(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>0.5</span>), (<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>21.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>17.3</span>), (<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>1</span>), (<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.3</span>, <span style=color:#ff9f43>0.3</span>), (<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.5</span>), (<span style=color:#ff9f43>2</span>, <span style=color:#ff9f43>4.5</span>)]
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> p, (minv, maxv) <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(x, bounds):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> minv <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>&lt;</span> maxv:
</span></span><span style=display:flex><span>            <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    prior <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>logpdf(MB, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>, <span style=color:#ff9f43>1</span>)
</span></span><span style=display:flex><span>    val <span style=color:#ff6ac1>=</span> <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> get_chi2(x) <span style=color:#ff6ac1>+</span> prior
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> np<span style=color:#ff6ac1>.</span>isnan(val):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> val
</span></span></code></pre></div></div><p>Lets check a simple minimisation over a grid to ensure things look alright before shipping it off to sample.</p><div class="expanded-code width-94" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>test_oms, test_MBs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>meshgrid(np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>0.7</span>, <span style=color:#ff9f43>30</span>), np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span><span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span><span style=color:#ff6ac1>+</span><span style=color:#ff9f43>1</span>, <span style=color:#ff9f43>30</span>))
</span></span><span style=display:flex><span>test_oms_flat, test_MBs_flat <span style=color:#ff6ac1>=</span> test_oms<span style=color:#ff6ac1>.</span>flatten(), test_MBs<span style=color:#ff6ac1>.</span>flatten()
</span></span><span style=display:flex><span>test_sigma_int <span style=color:#ff6ac1>=</span> test_sigma_c <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>ones(test_oms<span style=color:#ff6ac1>.</span>size) <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>0.1</span>
</span></span><span style=display:flex><span>test_mean_c <span style=color:#ff6ac1>=</span> test_sigma_c <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>test_beta <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>ones(test_oms<span style=color:#ff6ac1>.</span>size) <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>3.1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Generate points with varying Om and MB only</span>
</span></span><span style=display:flex><span>xs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((test_oms_flat, test_MBs_flat, test_sigma_int, 
</span></span><span style=display:flex><span>                test_mean_c, test_sigma_c, test_beta))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span>chi2s <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([get_chi2(x) <span style=color:#ff6ac1>for</span> x <span style=color:#ff6ac1>in</span> xs])<span style=color:#ff6ac1>.</span>reshape(test_oms<span style=color:#ff6ac1>.</span>shape)
</span></span></code></pre></div></div><pre><code>C:\Anaconda3\lib\site-packages\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply
  if __name__ == '__main__':
</code></pre><div class=width-76 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>contour(test_oms, test_MBs, chi2s, levels<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>30</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>scatter([<span style=color:#ff9f43>0.3</span>], [<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>], c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;r&#34;</span>, marker<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;*&#34;</span>, s<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>50</span>)
</span></span><span style=display:flex><span>cbar <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>colorbar()
</span></span><span style=display:flex><span>cbar<span style=color:#ff6ac1>.</span>set_label(<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\chi^2$&#34;</span>), plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\Omega_m$&#34;</span>), plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;$M_B$&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_24_0_hu1ad6d69b863fea90ba49dfe3bd31d782_422782_1920x0_resize_q90_h2_box_3.webp width=1920 height=1027 type=image/webp><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_24_0_hu1ad6d69b863fea90ba49dfe3bd31d782_422782_1920x0_resize_q90_box_3.png width=1920 height=1027 type=image/png><img width=2843 height=1521 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Alright, doesn&rsquo;t look too bad, our true point (the red star) is roughly the place of minimum $\chi^2$ value.</p><h2 id=sampling-the-likelihood>Sampling the likelihood</h2><p>Once again, we are turning to <code>emcee</code> to do the heavy lifting.</p><div class="expanded-code width-80" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> emcee
</span></span><span style=display:flex><span>ndim <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>6</span>  <span style=color:#78787e># How many parameters we are fitting. This is our dimensionality.</span>
</span></span><span style=display:flex><span>nwalkers <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>20</span>  <span style=color:#78787e># Keep this well above your dimensionality.</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>uniform(low<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.2</span>, high<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.4</span>, size<span style=color:#ff6ac1>=</span>(nwalkers, ndim))  <span style=color:#78787e># Start points</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>+=</span> np<span style=color:#ff6ac1>.</span>array([<span style=color:#ff9f43>0</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>2.8</span>])
</span></span></code></pre></div></div><div class=width-66 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sampler <span style=color:#ff6ac1>=</span> emcee<span style=color:#ff6ac1>.</span>EnsembleSampler(nwalkers, ndim, get_log_posterior)
</span></span><span style=display:flex><span>state <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>run_mcmc(p0, <span style=color:#ff9f43>2000</span>)
</span></span></code></pre></div></div><p>We can then extra samples from our chain&mldr;</p><div class=width-75 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>chain <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>chain[:, <span style=color:#ff9f43>400</span>:, :]
</span></span><span style=display:flex><span>flat_chain <span style=color:#ff6ac1>=</span> chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim))  <span style=color:#78787e># Stack the steps from each walker </span>
</span></span></code></pre></div></div><p>And with the samples on hand, lets throw them to ChainConsumer, to first confirm convergence of the walkers, and then check the posteriors.</p><div class="expanded-code width-93" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> chainconsumer <span style=color:#ff6ac1>import</span> ChainConsumer
</span></span><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>params <span style=color:#ff6ac1>=</span> [<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\Omega_m$&#34;</span>, <span style=color:#5af78e>&#34;$M_B$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\sigma_</span><span style=color:#5af78e>{int}</span><span style=color:#5af78e>$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\hat</span><span style=color:#5af78e>{c}</span><span style=color:#5af78e>$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\sigma_c$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\beta$&#34;</span>]
</span></span><span style=display:flex><span>truth <span style=color:#ff6ac1>=</span> [<span style=color:#ff9f43>0.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>, <span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>3.1</span>]
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>params, color<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;b&#34;</span>, kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(sampler<span style=color:#ff6ac1>.</span>chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim)), color<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;r&#34;</span>, kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot_walks(truth<span style=color:#ff6ac1>=</span>truth, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>4</span>));
</span></span></code></pre></div></div><p><div><figure class="img-invert rounded"><picture><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_31_0_hu61749c6e267545a5910ac683f2a8b7b3_436182_1687x0_resize_q90_h2_box_3.webp width=1687 height=831 type=image/webp><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_31_0_hu61749c6e267545a5910ac683f2a8b7b3_436182_1687x0_resize_q90_box_3.png width=1687 height=831 type=image/png><img width=1687 height=831 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Looks like they all converged quickly, let&rsquo;s go ahead and plot some contours.</p><div class="reduced-code width-42" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>params)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>configure(contour_labels<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;confidence&#34;</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot(truth<span style=color:#ff6ac1>=</span>truth, figsize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>summary <span style=color:#ff6ac1>=</span> c<span style=color:#ff6ac1>.</span>analysis<span style=color:#ff6ac1>.</span>get_summary()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> key, value <span style=color:#ff6ac1>in</span> summary<span style=color:#ff6ac1>.</span>items():
</span></span><span style=display:flex><span>    <span style=color:#ff5c57>print</span>(key, value)
</span></span></code></pre></div></div><pre><code>$\Omega_m$ [0.2631903131008057, 0.29061597591154054, 0.30997425330717543]
$M_B$ [-19.321238731508483, -19.30171461622203, -19.288605748148946]
$\sigma_{int}$ [0.13493630624153524, 0.14197489565813534, 0.149863741561936]
$\hat{c}$ [0.0012303218508645198, 0.003937307331830951, 0.0069427817061358844]
$\sigma_c$ [0.09716341194044988, 0.09960155368306237, 0.10317454723851435]
$\beta$ [2.9498499986818523, 3.0479769146439795, 3.104881022084486]
</code></pre><p><div><figure class="img-invert rounded"><picture><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_33_1_hu6f7280ed083744ffdc723263aa18d46d_557952_1920x0_resize_q90_h2_box_3.webp width=1920 height=1902 type=image/webp><source srcset=/tutorials/forwardmodelling/2020-04-08-ForwardModelling_files/2020-04-08-ForwardModelling_33_1_hu6f7280ed083744ffdc723263aa18d46d_557952_1920x0_resize_q90_box_3.png width=1920 height=1902 type=image/png><img width=2080 height=2060 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Which looks pretty good for a first pass and proof of concept. We note the imperfect recovery of $\sigma_{int}$, which is a story as old as time for our field. Alas.</p><hr><p>For your convenience, here&rsquo;s the code in one block:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> norm, uniform
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> astropy.cosmology <span style=color:#ff6ac1>import</span> FlatLambdaCDM
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> binned_statistic
</span></span><span style=display:flex><span>np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>seed(<span style=color:#ff9f43>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_fake_dist</span>(loc<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>, size<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span>):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; To make sure we dont need a suite of tests, 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    fake sampling a normal so that it is symmetric&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    cdfs <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>cdf(norm<span style=color:#ff6ac1>.</span>rvs(size<span style=color:#ff6ac1>=</span>size))
</span></span><span style=display:flex><span>    maxv <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>min</span>(cdfs<span style=color:#ff6ac1>.</span>max(), <span style=color:#ff9f43>0.999</span>)
</span></span><span style=display:flex><span>    vals <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>ppf(np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> maxv, maxv, size)) <span style=color:#ff6ac1>*</span> scale <span style=color:#ff6ac1>+</span> loc
</span></span><span style=display:flex><span>    np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>shuffle(vals)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> vals
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_events</span>(om<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, MB<span style=color:#ff6ac1>=-</span><span style=color:#ff9f43>19.3</span>, sigma_int<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, mean_c<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, 
</span></span><span style=display:flex><span>               sigma_c<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, beta<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>3.1</span>, num<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5000</span>):
</span></span><span style=display:flex><span>    zs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>1.05</span>, num)   
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#78787e># I sample bit by bit in redshift space to make sure our posterior </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># should be centered roughly on the true value, otherwise we&#39;d have </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># to run a suite of realisations to test the statistics rigorously.</span>
</span></span><span style=display:flex><span>    bins <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>100</span>
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>int</span>(num <span style=color:#ff6ac1>/</span> bins)
</span></span><span style=display:flex><span>    deltas <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([])
</span></span><span style=display:flex><span>    cs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([])
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> i <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>range</span>(bins):
</span></span><span style=display:flex><span>        deltas <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>concatenate((deltas, get_fake_dist(scale<span style=color:#ff6ac1>=</span>sigma_int, size<span style=color:#ff6ac1>=</span>n)))
</span></span><span style=display:flex><span>        cs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>concatenate((cs, get_fake_dist(loc<span style=color:#ff6ac1>=</span>mean_c, scale<span style=color:#ff6ac1>=</span>sigma_c, size<span style=color:#ff6ac1>=</span>n)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    MBs <span style=color:#ff6ac1>=</span> MB <span style=color:#ff6ac1>+</span> deltas <span style=color:#ff6ac1>+</span> beta <span style=color:#ff6ac1>*</span> cs
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, om)<span style=color:#ff6ac1>.</span>distmod(zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    mb <span style=color:#ff6ac1>=</span> distmod <span style=color:#ff6ac1>+</span> MBs
</span></span><span style=display:flex><span>    <span style=color:#78787e># Emulate some probabilistic selection effect</span>
</span></span><span style=display:flex><span>    mask <span style=color:#ff6ac1>=</span> (mb <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>rvs(scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, size<span style=color:#ff6ac1>=</span>num)) <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>24</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> mb[mask], zs[mask], cs[mask]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_mbs, data_zs, data_cs <span style=color:#ff6ac1>=</span> get_events()
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>3</span>))
</span></span><span style=display:flex><span>h <span style=color:#ff6ac1>=</span> ax<span style=color:#ff6ac1>.</span>scatter(data_zs, data_mbs, c<span style=color:#ff6ac1>=</span>data_cs, cmap<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;coolwarm&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>colorbar(h)<span style=color:#ff6ac1>.</span>set_label(<span style=color:#5af78e>&#34;colour&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_xlabel(<span style=color:#5af78e>&#34;$z$&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_ylabel(<span style=color:#5af78e>&#34;$m_B$&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_sim_events</span>(num<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>100000</span>):
</span></span><span style=display:flex><span>    MBs <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>21.3</span>, <span style=color:#ff9f43>4</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    cs <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>1</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    betas <span style=color:#ff6ac1>=</span> uniform<span style=color:#ff6ac1>.</span>rvs(<span style=color:#ff9f43>2</span>, <span style=color:#ff9f43>4.5</span>, size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    zs <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.05</span> <span style=color:#ff6ac1>+</span> uniform<span style=color:#ff6ac1>.</span>rvs(size<span style=color:#ff6ac1>=</span>num)
</span></span><span style=display:flex><span>    <span style=color:#78787e># The value here for om doesnt actually matter</span>
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, <span style=color:#ff9f43>0.3</span>)<span style=color:#ff6ac1>.</span>distmod(zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    mb <span style=color:#ff6ac1>=</span> distmod <span style=color:#ff6ac1>+</span> MBs <span style=color:#ff6ac1>+</span> betas <span style=color:#ff6ac1>*</span> cs
</span></span><span style=display:flex><span>    <span style=color:#78787e># Emulate some probabilistic selection effect</span>
</span></span><span style=display:flex><span>    mask <span style=color:#ff6ac1>=</span> (mb <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>rvs(scale<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>, size<span style=color:#ff6ac1>=</span>num)) <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>24</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> mb[mask], zs[mask], betas[mask], cs[mask]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sim_mbs, sim_zs, sim_betas, sim_cs <span style=color:#ff6ac1>=</span> get_sim_events()
</span></span><span style=display:flex><span>fig, ax <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>subplots(figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>3</span>))
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>hist2d(sim_zs, sim_mbs, bins<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>50</span>)
</span></span><span style=display:flex><span>ax<span style=color:#ff6ac1>.</span>set_xlabel(<span style=color:#5af78e>&#34;$z$&#34;</span>), ax<span style=color:#ff6ac1>.</span>set_ylabel(<span style=color:#5af78e>&#34;$m_B$&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>reweight</span>(sim_mbs, sim_zs, sim_cs, om, MB, sigma_int, mean_c, sigma_c, beta):
</span></span><span style=display:flex><span>    <span style=color:#78787e># Step 1: Use om to move from observer frame to rest frame</span>
</span></span><span style=display:flex><span>    distmod <span style=color:#ff6ac1>=</span> FlatLambdaCDM(<span style=color:#ff9f43>70</span>, om)<span style=color:#ff6ac1>.</span>distmod(sim_zs)<span style=color:#ff6ac1>.</span>value
</span></span><span style=display:flex><span>    sim_MBs <span style=color:#ff6ac1>=</span> sim_mbs <span style=color:#ff6ac1>-</span> distmod <span style=color:#ff6ac1>-</span> beta <span style=color:#ff6ac1>*</span> sim_cs
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#78787e># Use top-level parameters to get pdf of simulation points</span>
</span></span><span style=display:flex><span>    weights <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>logpdf(sim_MBs, MB, sigma_int) <span style=color:#ff6ac1>+</span> norm<span style=color:#ff6ac1>.</span>logpdf(sim_cs, mean_c, sigma_c)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> np<span style=color:#ff6ac1>.</span>exp(weights)
</span></span><span style=display:flex><span><span style=color:#78787e># Define some histogram edges</span>
</span></span><span style=display:flex><span>mb_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>13</span>, <span style=color:#ff9f43>26</span>, <span style=color:#ff9f43>31</span>)
</span></span><span style=display:flex><span>z_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>1.05</span>, <span style=color:#ff9f43>31</span>)
</span></span><span style=display:flex><span>c_edges <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>0.5</span>, <span style=color:#ff9f43>11</span>)
</span></span><span style=display:flex><span>mbc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (mb_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> mb_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>zc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (z_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> z_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>cc <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> (c_edges[:<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>] <span style=color:#ff6ac1>+</span> c_edges[<span style=color:#ff9f43>1</span>:])
</span></span><span style=display:flex><span>bins <span style=color:#ff6ac1>=</span> [mb_edges, z_edges, c_edges]
</span></span><span style=display:flex><span>data <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((data_mbs, data_zs, data_cs))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(data<span style=color:#ff6ac1>.</span>shape)
</span></span><span style=display:flex><span>thresh <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>2</span>  <span style=color:#78787e># If you dont have more than 2 samples, dont count it</span>
</span></span><span style=display:flex><span>hist, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(data, bins<span style=color:#ff6ac1>=</span>[mb_edges, z_edges, c_edges])
</span></span><span style=display:flex><span>delta_vol <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>diff(mb_edges)[<span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>*</span> np<span style=color:#ff6ac1>.</span>diff(z_edges)[<span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>*</span> np<span style=color:#ff6ac1>.</span>diff(c_edges)[<span style=color:#ff9f43>0</span>]
</span></span><span style=display:flex><span>volume <span style=color:#ff6ac1>=</span> hist<span style=color:#ff6ac1>.</span>sum() <span style=color:#ff6ac1>*</span> delta_vol
</span></span><span style=display:flex><span>hist_err <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(hist)
</span></span><span style=display:flex><span>hist_err[hist_err <span style=color:#ff6ac1>&lt;</span> thresh] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>hist_err <span style=color:#ff6ac1>=</span> hist_err <span style=color:#ff6ac1>/</span> volume
</span></span><span style=display:flex><span>hist <span style=color:#ff6ac1>=</span> hist <span style=color:#ff6ac1>/</span> volume
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sim <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((sim_mbs, sim_zs, sim_cs))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span>sim_count, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(sim, bins<span style=color:#ff6ac1>=</span>[mb_edges, z_edges, c_edges])
</span></span><span style=display:flex><span>sim_num_err <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(sim_count)
</span></span><span style=display:flex><span>sim_num_err[sim_num_err <span style=color:#ff6ac1>&lt;</span> thresh] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>sim_err_ratio <span style=color:#ff6ac1>=</span> sim_num_err <span style=color:#ff6ac1>/</span> sim_count
</span></span><span style=display:flex><span>sim_err_ratio[sim_count <span style=color:#ff6ac1>==</span> <span style=color:#ff9f43>0</span>] <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_chi2</span>(x, plot<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>):
</span></span><span style=display:flex><span>    om, MB, sigma_int, mean_c, sigma_c, beta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#78787e># Add a prior onto MB to help fitting</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    weights <span style=color:#ff6ac1>=</span> reweight(sim_mbs, sim_zs, sim_cs, om, MB, sigma_int, mean_c, sigma_c, beta)
</span></span><span style=display:flex><span>    <span style=color:#78787e># Now need a likelihood combining data and simulation. This is super simple, we&#39;d probably </span>
</span></span><span style=display:flex><span>    <span style=color:#78787e># want something like 1712.01293 in a real analysis where we combine MC and Poisson uncert.</span>
</span></span><span style=display:flex><span>    sim_hist, _ <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>histogramdd(sim, bins<span style=color:#ff6ac1>=</span>bins, weights<span style=color:#ff6ac1>=</span>weights, density<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>True</span>)
</span></span><span style=display:flex><span>    sim_err <span style=color:#ff6ac1>=</span> sim_hist <span style=color:#ff6ac1>*</span> sim_err_ratio
</span></span><span style=display:flex><span>    chi2 <span style=color:#ff6ac1>=</span> ((sim_hist <span style=color:#ff6ac1>-</span> hist)<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>/</span> (hist_err<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> sim_err<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>))
</span></span><span style=display:flex><span>    chi2 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>nan_to_num(chi2, copy<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>)<span style=color:#ff6ac1>.</span>sum()
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> chi2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_log_posterior</span>(x):
</span></span><span style=display:flex><span>    om, MB, sigma_int, mean_c, sigma_c, beta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    bounds <span style=color:#ff6ac1>=</span> [(<span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>0.5</span>), (<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>21.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>17.3</span>), (<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>1</span>), (<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.3</span>, <span style=color:#ff9f43>0.3</span>), (<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.5</span>), (<span style=color:#ff9f43>2</span>, <span style=color:#ff9f43>4.5</span>)]
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> p, (minv, maxv) <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>zip</span>(x, bounds):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> minv <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>&lt;</span> maxv:
</span></span><span style=display:flex><span>            <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    prior <span style=color:#ff6ac1>=</span> norm<span style=color:#ff6ac1>.</span>logpdf(MB, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>, <span style=color:#ff9f43>1</span>)
</span></span><span style=display:flex><span>    val <span style=color:#ff6ac1>=</span> <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.5</span> <span style=color:#ff6ac1>*</span> get_chi2(x) <span style=color:#ff6ac1>+</span> prior
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> np<span style=color:#ff6ac1>.</span>isnan(val):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> val
</span></span><span style=display:flex><span>test_oms, test_MBs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>meshgrid(np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>0.7</span>, <span style=color:#ff9f43>30</span>), np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span><span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span><span style=color:#ff6ac1>+</span><span style=color:#ff9f43>1</span>, <span style=color:#ff9f43>30</span>))
</span></span><span style=display:flex><span>test_oms_flat, test_MBs_flat <span style=color:#ff6ac1>=</span> test_oms<span style=color:#ff6ac1>.</span>flatten(), test_MBs<span style=color:#ff6ac1>.</span>flatten()
</span></span><span style=display:flex><span>test_sigma_int <span style=color:#ff6ac1>=</span> test_sigma_c <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>ones(test_oms<span style=color:#ff6ac1>.</span>size) <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>0.1</span>
</span></span><span style=display:flex><span>test_mean_c <span style=color:#ff6ac1>=</span> test_sigma_c <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>test_beta <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>ones(test_oms<span style=color:#ff6ac1>.</span>size) <span style=color:#ff6ac1>*</span> <span style=color:#ff9f43>3.1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Generate points with varying Om and MB only</span>
</span></span><span style=display:flex><span>xs <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>vstack((test_oms_flat, test_MBs_flat, test_sigma_int, 
</span></span><span style=display:flex><span>                test_mean_c, test_sigma_c, test_beta))<span style=color:#ff6ac1>.</span>T
</span></span><span style=display:flex><span>chi2s <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>array([get_chi2(x) <span style=color:#ff6ac1>for</span> x <span style=color:#ff6ac1>in</span> xs])<span style=color:#ff6ac1>.</span>reshape(test_oms<span style=color:#ff6ac1>.</span>shape)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>contour(test_oms, test_MBs, chi2s, levels<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>30</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>scatter([<span style=color:#ff9f43>0.3</span>], [<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>], c<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;r&#34;</span>, marker<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;*&#34;</span>, s<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>50</span>)
</span></span><span style=display:flex><span>cbar <span style=color:#ff6ac1>=</span> plt<span style=color:#ff6ac1>.</span>colorbar()
</span></span><span style=display:flex><span>cbar<span style=color:#ff6ac1>.</span>set_label(<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\chi^2$&#34;</span>), plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\Omega_m$&#34;</span>), plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;$M_B$&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> emcee
</span></span><span style=display:flex><span>ndim <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>6</span>  <span style=color:#78787e># How many parameters we are fitting. This is our dimensionality.</span>
</span></span><span style=display:flex><span>nwalkers <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>20</span>  <span style=color:#78787e># Keep this well above your dimensionality.</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>uniform(low<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.2</span>, high<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.4</span>, size<span style=color:#ff6ac1>=</span>(nwalkers, ndim))  <span style=color:#78787e># Start points</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>+=</span> np<span style=color:#ff6ac1>.</span>array([<span style=color:#ff9f43>0</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>2.8</span>])
</span></span><span style=display:flex><span>sampler <span style=color:#ff6ac1>=</span> emcee<span style=color:#ff6ac1>.</span>EnsembleSampler(nwalkers, ndim, get_log_posterior)
</span></span><span style=display:flex><span>state <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>run_mcmc(p0, <span style=color:#ff9f43>2000</span>)
</span></span><span style=display:flex><span>chain <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>chain[:, <span style=color:#ff9f43>400</span>:, :]
</span></span><span style=display:flex><span>flat_chain <span style=color:#ff6ac1>=</span> chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim))  <span style=color:#78787e># Stack the steps from each walker </span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> chainconsumer <span style=color:#ff6ac1>import</span> ChainConsumer
</span></span><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>params <span style=color:#ff6ac1>=</span> [<span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\Omega_m$&#34;</span>, <span style=color:#5af78e>&#34;$M_B$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\sigma_</span><span style=color:#5af78e>{int}</span><span style=color:#5af78e>$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\hat</span><span style=color:#5af78e>{c}</span><span style=color:#5af78e>$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\sigma_c$&#34;</span>, <span style=color:#5af78e>r</span><span style=color:#5af78e>&#34;$\beta$&#34;</span>]
</span></span><span style=display:flex><span>truth <span style=color:#ff6ac1>=</span> [<span style=color:#ff9f43>0.3</span>, <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>19.3</span>, <span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.1</span>, <span style=color:#ff9f43>3.1</span>]
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>params, color<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;b&#34;</span>, kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(sampler<span style=color:#ff6ac1>.</span>chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim)), color<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;r&#34;</span>, kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot_walks(truth<span style=color:#ff6ac1>=</span>truth, figsize<span style=color:#ff6ac1>=</span>(<span style=color:#ff9f43>8</span>,<span style=color:#ff9f43>4</span>));
</span></span><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>params)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>configure(contour_labels<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;confidence&#34;</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot(truth<span style=color:#ff6ac1>=</span>truth, figsize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>summary <span style=color:#ff6ac1>=</span> c<span style=color:#ff6ac1>.</span>analysis<span style=color:#ff6ac1>.</span>get_summary()
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> key, value <span style=color:#ff6ac1>in</span> summary<span style=color:#ff6ac1>.</span>items():
</span></span><span style=display:flex><span>    <span style=color:#ff5c57>print</span>(key, value)
</span></span></code></pre></div><div class="relative max-w-xl mx-auto my-20"><div class="fancy_card horizontal"><div class=card_translator><div class="card_rotator tiny_rot card_layer"><div class="card_layer newsletter p-2"><div class="newsletter-inner h-full"><div class="relative h-full sib-form-container" id=sib-form-container><div class="mb-6 lg:mb-12 text-center"><h3 class="text-main-200 mb-2 lg:mb-8">Stay in the loop!</h3><p class="text-main-100 text-lg text-opacity-70">For new releases, exclusive giveaways, and reviews.</p></div><form action="https://Cosmiccoding.us5.list-manage.com/subscribe/post?u=aebe5de1d2e40dccb3aeca491&id=3987dd4a1f" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate w-full" target=_blank novalidate><div><input type=email class="w-full appearance-none bg-main-600 mb-4 border border-main-600 bg-opacity-5 focus:border-main-300 rounded-sm px-4 py-3 text-main-100 placeholder-main-100 required" placeholder="Your best email" aria-label="Your best email" name=EMAIL required data-required=true id=EMAIL><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_aebe5de1d2e40dccb3aeca491_3987dd4a1f tabindex=-1></div><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class="button btn bg-main-600 hover:bg-main-400 shadow w-full"></div><p id=mce-error-response style=display:none class="text-center mt-2 opacity-50 text-main-200">There was a problem, please try again.</p><p id=mce-success-response style=display:none class="text-center mt-2 opacity-50 text-main-200">Thanks mate, won't let ya down.</p></form></div></div></div><div class="card_layer card_effect card_soft_glare" style=pointer-events:none></div></div></div></div></div></div><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div><script language=javascript type=text/javascript src=https://cosmiccoding.com.au/js/main.min.11673d10a962fb5205229607e62ea1d23424d35dad33db7bfe2a09a63d5409fa.js></script>
<script async defer src="https://www.googletagmanager.com/gtag/js?id=UA-72691106-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-72691106-1")</script></div></body></html>