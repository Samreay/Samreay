<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>A/B Test Significance in Python - Samuel Hinton</title><link rel=stylesheet href="https://cosmiccoding.com.au/css/main.min.7fbf65bef988e0cecd6d148a59756085deed3c480729d260d0a30b282b1d7da8.css" integrity="sha256-f79lvvmI4M7NbRSKWXVghd7tPEgHKdJg0KMLKCsdfag="><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel="shortcut icon" href=https://cosmiccoding.com.au/img/favicon.png type=image/x-icon></head><meta name=description content="Using Python to determine just how confident we are in our A/B test results"><meta name=robots content="noodp"><link rel=canonical href=https://cosmiccoding.com.au/tutorials/abtests/><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cosmiccoding.com.au/tutorials/abtests/cover.jpg"><meta name=twitter:title content="A/B Test Significance in Python"><meta name=twitter:description content="Using Python to determine just how confident we are in our A/B test results"><meta property="og:title" content="A/B Test Significance in Python"><meta property="og:description" content="Using Python to determine just how confident we are in our A/B test results"><meta property="og:type" content="article"><meta property="og:url" content="https://cosmiccoding.com.au/tutorials/abtests/"><meta property="og:image" content="https://cosmiccoding.com.au/tutorials/abtests/cover.jpg"><meta property="article:section" content="tutorials"><meta property="article:published_time" content="2020-01-12T00:00:00+00:00"><meta property="article:modified_time" content="2020-01-12T00:00:00+00:00"><meta property="article:section" content="tutorial"><meta property="article:published_time" content="2020-01-12 00:00:00 +0000 UTC"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"A\/B Test Significance in Python","genre":"tutorial","url":"https:\/\/cosmiccoding.com.au\/tutorials\/abtests\/","datePublished":"2020-01-12 00:00:00 \u002b0000 UTC","description":"Using Python to determine just how confident we are in our A\/B test results","author":{"@type":"Person","name":""}}</script><body><div class="flex flex-col min-h-screen overflow-hidden"><header class="absolute w-full z-30"><div class="max-w-6xl mx-auto px-4 sm:px-6"><div class="flex items-center justify-between h-20"><div class="flex-shrink-0 mr-4"><a class=block href=/ aria-label="Samuel Hinton"><h2 class=logo>SRH</h2></a></div><nav class="hidden md:flex md:flex-grow"><ul class="flex flex-grow justify-end flex-wrap items-center"><li><a href=/#books class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Books</a></li><li><a href=/reviews class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Reviews</a></li><li><a href=/tutorials class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Tutorials</a></li><li><a href=/blogs class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Blog</a></li><li><a href=/#courses class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">CV</a></li></ul></nav><div class=md:hidden x-data="{ expanded: false }"><button class=hamburger :class="{ 'active': expanded }" @click.stop="expanded = !expanded" aria-controls=mobile-nav :aria-expanded=expanded>
<span class=sr-only>Menu</span><svg class="w-6 h-6 fill-current text-gray-300 hover:text-gray-200 transition duration-150 ease-in-out" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><rect y="4" width="24" height="2" rx="1"/><rect y="11" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg></button><nav id=mobile-nav class="absolute top-full z-20 left-0 w-full px-4 sm:px-6 overflow-hidden transition-all duration-300 ease-in-out" x-ref=mobileNav :style="expanded ? 'max-height: ' + $refs.mobileNav.scrollHeight + 'px; opacity: 1' : 'max-height: 0; opacity: .8'" @click.away="expanded = false" @keydown.escape.window="expanded = false" x-cloak><ul class="bg-gray-800 px-4 py-2"><li><a href=/#books class="flex text-gray-300 hover:text-gray-200 py-2">Books</a></li><li><a href=/reviews class="flex text-gray-300 hover:text-gray-200 py-2">Reviews</a></li><li><a href=/tutorials class="flex text-gray-300 hover:text-gray-200 py-2">Tutorials</a></li><li><a href=/blogs class="flex text-gray-300 hover:text-gray-200 py-2">Blog</a></li><li><a href=/#courses class="flex text-gray-300 hover:text-gray-200 py-2">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="flex text-gray-300 hover:text-gray-200 py-2">CV</a></li></ul></nav></div></div></div></header><div class=flex-grow><div id=post-container class="content content-wider blog-post relative"><div class="section-header blog"><h1 class=title>A/B Test Significance in Python</h1><p>6th January 2020</p><p>Using Python to determine just how confident we are in our A/B test results</p></div><div><ul class="grid gap-6 w-full md:grid-cols-2" style=list-style:none;padding-left:0><li><input type=radio id=show-code name=code-toggle value=show-code class="hidden peer" onchange=clickCheckbox(this) required checked>
<label for=show-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Show me everything!</div><div class="w-full text-center text-sm">Oh yeah, coding time.</div></div></label></li><li><input type=radio id=hide-code name=code-toggle value=hide-code class="hidden peer" onchange=clickCheckbox(this)>
<label for=hide-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Just the plots</div><div class="w-full text-center text-sm">Code is nasty.</div></div></label></li></ul></div><script>function clickCheckbox(e){e.id=="show-code"?document.getElementById("post-container").classList.remove("hide-code"):document.getElementById("post-container").classList.add("hide-code")}</script><p>Recently I was asked to talk about A/B tests for my <a href="https://www.udemy.com/course/python-for-statistical-analysis/?referralCode=76158B46FA5EB57C38EB">Python for Statistical Analysis course</a>. Given my travel schedule, leaving me bereft of my microphone, I thought it would be better to condense down A/B tests into a tutorial or two.</p><p>In this little write up, we&rsquo;ll cover what an A/B test is, run through it in first principles with frequentist hypothesis testing, apply some existing scipy tests to speed the process up, and then at the end we&rsquo;ll approach the problem in a Bayesian framework.</p><h2 id=what-is-an-ab-test>What is an AB test?</h2><p>Imagine you&rsquo;re in charge of a website to optimise sales. You have the current version of the website, but aren&rsquo;t happy with it. The &ldquo;Buy now&rdquo; button is not obvious to the user, it&rsquo;s hidden away, so you want to try making it bigger and brighter, maybe that will increase conversion. But you also care about statistical rigour (an odd combination to be sure). So you set up your website so that half the people are directed to the old website, and half to one where you&rsquo;ve made your change. You have data from both, and want to know, with confidence, <em>&ldquo;Does the change I made increase conversion?&rdquo;</em>.</p><p><div><figure class="img-main img-invert img-poster rounded"><picture><source srcset=/tutorials/abtests/cover_hu88074195e0689a15b6db2afbd0317269_39975_1000x0_resize_q90_h2_box.webp width=1000 height=500 type=image/webp><source srcset=/tutorials/abtests/cover.jpg width=1000 height=500 type=image/jpg><img width=1000 height=500 loading=lazy decoding=async alt=jpeg src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>This is an A/B test. Often this is used interchangably with the term &ldquo;split testing&rdquo;, though in general A/B tests test small changes, and split testing might be when you present two entirely different websites to the user.</p><p><strong>Why not just change the website and monitor it for a week?</strong> Good question - by having two sites active at once and randomly directing users to one or the other, you control for all other variables. If one week later puts you the week before Christmas, this will impact sales, and you might draw the wrong conclusion because of these confounding effects.</p><p><strong>Why is it not an A/B/C test?</strong> Well, you can have as many perturbations running as you want, but got to keep the name simple. The more perturbations you try though, the smaller a number of samples you&rsquo;ll have for each case, and the harder it will be to draw statistically significant conclusions.</p><p>Now, A/B tests can test anything you want, but common ones are click through/conversion, bounce rate, and how long you spend on the page. For this example, let us assume we want to optimise conversion, which in our case is clicking the &ldquo;Add to cart&rdquo; button above.</p><p>Let us assume you have 1000 users, 550 were directed to site A, 450 to site B. In site A, 48 users converted. In site B, 56 users converted. <strong>Is this a statistically significant result?</strong></p><div class="reduced-code width-49" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>num_a, num_b <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>550</span>, <span style=color:#ff9f43>450</span>
</span></span><span style=display:flex><span>click_a, click_b <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>48</span>, <span style=color:#ff9f43>56</span>
</span></span><span style=display:flex><span>rate_a, rate_b <span style=color:#ff6ac1>=</span> click_a <span style=color:#ff6ac1>/</span> num_a, click_b <span style=color:#ff6ac1>/</span> num_b
</span></span></code></pre></div></div><p>For a TL;DR - &ldquo;just give me the answer&rdquo;, if you want to test the hypothesis the click-through-rate (CTR) of B > A, then <a href=#Mann-Whitney-U-test>jump to the Mann-Whitney U test</a>.</p><h2 id=modelling-click-through>Modelling click through</h2><p>You can click a button, or not. Two discrete options are available, so this is a textbook binomial distribution, with some unknown rate for site A and site B. We don&rsquo;t know the true click rate, but we can estimate it using our small sample.</p><div class="reduced-code width-55" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> binom
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Determine the probability of having x click throughs</span>
</span></span><span style=display:flex><span>clicks <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>arange(<span style=color:#ff9f43>20</span>, <span style=color:#ff9f43>80</span>)
</span></span><span style=display:flex><span>prob_a <span style=color:#ff6ac1>=</span> binom(num_a, rate_a)<span style=color:#ff6ac1>.</span>pmf(clicks)
</span></span><span style=display:flex><span>prob_b <span style=color:#ff6ac1>=</span> binom(num_b, rate_b)<span style=color:#ff6ac1>.</span>pmf(clicks)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Make the bar plots.</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>bar(clicks, prob_a, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;A&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>bar(clicks, prob_b, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;B&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>&#34;Num converted&#34;</span>); plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;Probability&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_6_0_huaa1b8a9a4352c195816960d52a197321_69946_1920x0_resize_q90_h2_box_3.webp width=1920 height=1014 type=image/webp><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_6_0.png width=2832 height=1495 type=image/png><img width=2832 height=1495 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>So we can see here that B has an edge when looking at the number of users, but its certaintly possible if we pick two random points according to the histograms for A and B, that A might actually be higher than B! But of course, we fundamentally <strong>do not care</strong> about the number of users, we need to move from the number of users to looking at the click through rate.</p><h1 id=lets-get-normal>Let&rsquo;s get normal</h1><p>Sure, we <em>can</em> work with binomial distributions in this case. And Poisson distributions in the &ldquo;How long were you on the site&rdquo; case. We could swap distributions for every question&mldr; or we can invoke the Central Limit Theorem. As we&rsquo;re interested in the <strong>average</strong> conversion, or <strong>average</strong> time spent on the site, this averaging of an underlying distribution means our final estimate will be well approximated by a normal distribution.</p><p>So let&rsquo;s reformulate, <a href=https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation>using the normal approximation here</a>:</p><div class="reduced-code width-57" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> norm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Where does this come from? See the link above.</span>
</span></span><span style=display:flex><span>std_a <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_a <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> num_a)
</span></span><span style=display:flex><span>std_b <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_b <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> num_b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>click_rate <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.2</span>, <span style=color:#ff9f43>200</span>)
</span></span><span style=display:flex><span>prob_a <span style=color:#ff6ac1>=</span> norm(rate_a, std_a)<span style=color:#ff6ac1>.</span>pdf(click_rate)
</span></span><span style=display:flex><span>prob_b <span style=color:#ff6ac1>=</span> norm(rate_b, std_b)<span style=color:#ff6ac1>.</span>pdf(click_rate)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Make the bar plots.</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(click_rate, prob_a, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;A&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(click_rate, prob_b, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;B&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>&#34;Conversion rate&#34;</span>); plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;Probability&#34;</span>);
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_8_0_huac3cdae140aaca68efc8d9739b74c7bf_121293_1920x0_resize_q90_h2_box_3.webp width=1920 height=1034 type=image/webp><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_8_0.png width=2776 height=1495 type=image/png><img width=2776 height=1495 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>This is also a better plot than the first one, because we&rsquo;ve removed the confusing effect of site A and site B having a slightly different number of visitors had.</p><p>To restate what the plot above is showing - it is showing, given the data we collected, the probability that the <em>actual</em> conversion rate for A and B was a certain value.</p><p>So our question is still the same: What is the chance that the <em>actual</em> CTR from B is higher than the CTR of A. Ie, the chance a draw from the B distribution above is greater than a draw from the A distribution. And is that significant?</p><p>To answer this, let us utilise the handy fact that the sum (or difference) of normally distributed random numbers is also a normal. <a href=https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables#Independent_random_variables>See here for the proof</a>, but the math is as follows:</p><p>$$ P(b-a) = \mathcal{N}(\mu_B - \mu_A, \sqrt{\sigma_A^2 + \sigma_B^2}) $$</p><p>This is simple - take the difference in the means and sum the variance. We&rsquo;ll do two things below: First, get the z-score, and second, plot the proper distribution.</p><div class=width-75 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># The z-score is really all we need if we want a number</span>
</span></span><span style=display:flex><span>z_score <span style=color:#ff6ac1>=</span> (rate_b <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;z-score is </span><span style=color:#5af78e>{</span>z_score<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>, with p-value </span><span style=color:#5af78e>{</span>norm()<span style=color:#ff6ac1>.</span>sf(z_score)<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># But I want a plot as well</span>
</span></span><span style=display:flex><span>p <span style=color:#ff6ac1>=</span> norm(rate_b <span style=color:#ff6ac1>-</span> rate_a, np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>))
</span></span><span style=display:flex><span>x <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>0.15</span>, <span style=color:#ff9f43>1000</span>)
</span></span><span style=display:flex><span>y <span style=color:#ff6ac1>=</span> p<span style=color:#ff6ac1>.</span>pdf(x)
</span></span><span style=display:flex><span>area_under_curve <span style=color:#ff6ac1>=</span> p<span style=color:#ff6ac1>.</span>sf(<span style=color:#ff9f43>0</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(x, y, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;PDF&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>fill_between(x, <span style=color:#ff9f43>0</span>, y, where<span style=color:#ff6ac1>=</span>x<span style=color:#ff6ac1>&gt;</span><span style=color:#ff9f43>0</span>, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Prob(b&gt;a)&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>annotate(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Area=</span><span style=color:#5af78e>{</span>area_under_curve<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>, (<span style=color:#ff9f43>0.02</span>, <span style=color:#ff9f43>5</span>))
</span></span></code></pre></div></div><pre><code>z-score is 1.890, with p-value 0.029
</code></pre><p><div><figure class=rounded><picture><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_10_1_hudbf362ad555bf3c7da5a72dc6aee9ff2_125807_1920x0_resize_q90_h2_box_3.webp width=1920 height=1014 type=image/webp><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_10_1.png width=2832 height=1495 type=image/png><img width=2832 height=1495 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>Great! So, how to phrase this result? Using our frequentist approach so far, we would say that given the null hypothesis is true (that B is less then or equal to A), we would expect to get this result or a result more extreme only 2.9% of the time. As that is a significant result (typically p &lt; 5%), we reject the null hypothesis, and state that we have evidence that B > A.</p><p>We should explicitly note here that this is a one-tailed test - the question we&rsquo;ve asked is if B > A. An alterative is the two-tailed test, where we just want to discriminate that B is <em>different</em> to A. In that case, our p-value is actually $2 \times 2.9 = 5.8$ percent (as we have two tails, not one), and we would want more samples before rejecting the null hypothesis if we stick to the p-value of 0.05 threshold.</p><p>However, we&rsquo;ve made a lot of plots for this to try and explain the concept. You can easily write a tiny function to simplify all of this. Whether you want the confidence or the p-value just means changing the final <code>norm.cdf</code> to <code>norm.sf</code>.</p><div class=width-62 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_confidence_ab_test</span>(click_a, num_a, click_b, num_b):
</span></span><span style=display:flex><span>    rate_a <span style=color:#ff6ac1>=</span> click_a <span style=color:#ff6ac1>/</span> num_a
</span></span><span style=display:flex><span>    rate_b <span style=color:#ff6ac1>=</span> click_b <span style=color:#ff6ac1>/</span> num_b
</span></span><span style=display:flex><span>    std_a <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_a <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> num_a)
</span></span><span style=display:flex><span>    std_b <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_b <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> num_b)
</span></span><span style=display:flex><span>    z_score <span style=color:#ff6ac1>=</span> (rate_b <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> norm<span style=color:#ff6ac1>.</span>cdf(z_score)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(get_confidence_ab_test(click_a, num_a, click_b, num_b))
</span></span></code></pre></div></div><pre><code>0.9705973498275782
</code></pre><h1 id=can-we-check-weve-done-the-right-thing>Can we check we&rsquo;ve done the right thing?</h1><p>So what if we&rsquo;re not confident that we&rsquo;ve done the math perfectly? Is there a way we can brute force a check? Turns out, there is, and its simplest to start from the rates and our normal approximation.</p><div class="reduced-code width-56" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># Draw 10000 samples of possible rates for a and b</span>
</span></span><span style=display:flex><span>n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>10000</span>
</span></span><span style=display:flex><span>rates_a <span style=color:#ff6ac1>=</span> norm(rate_a, std_a)<span style=color:#ff6ac1>.</span>rvs(n)
</span></span><span style=display:flex><span>rates_b <span style=color:#ff6ac1>=</span> norm(rate_b, std_b)<span style=color:#ff6ac1>.</span>rvs(n)
</span></span><span style=display:flex><span>b_better <span style=color:#ff6ac1>=</span> (rates_b <span style=color:#ff6ac1>&gt;</span> rates_a)<span style=color:#ff6ac1>.</span>mean()
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;B is better than A </span><span style=color:#5af78e>{</span>b_better<span style=color:#5af78e>:</span><span style=color:#5af78e>0.1%</span><span style=color:#5af78e>}</span><span style=color:#5af78e> of the time&#34;</span>)
</span></span></code></pre></div></div><pre><code>B is better than A 97.1% of the time
</code></pre><p>Which, rephrased to the language of before, is that A > B only ~3% of the time, which is statistically significant such that we can reject our hypothesis (that A &lt;= B).</p><p>Often this is the way we would actually do more complicated analyses, when there isn&rsquo;t an analytic solution and its easiest to just simulate the process. The power of modern computing opens many doors!</p><h1 id=can-we-do-this-test-even-faster>Can we do this test even faster?</h1><p>We&rsquo;ve done some math ourselves, taking things down to a normal distribution and doing a basic difference of means test. But <code>scipy</code> has lots of stuff hidden inside it to make our lives easier. Here imagine we have the raw results of click through, 0 or 1, as our distribution, and we want to use an inbuild t-test.</p><p>For example, if we had 5 users for site A, we might have <code>[1, 0, 1, 0, 0]</code> if only two users clicked through.</p><h2 id=welschs-t-test>Welsch&rsquo;s t-test</h2><div class="expanded-code width-98" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> ttest_ind
</span></span><span style=display:flex><span>a_dist <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(num_a)
</span></span><span style=display:flex><span>a_dist[:click_a] <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>1</span>
</span></span><span style=display:flex><span>b_dist <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(num_b)
</span></span><span style=display:flex><span>b_dist[:click_b] <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>1</span>
</span></span><span style=display:flex><span>zscore, prob <span style=color:#ff6ac1>=</span> ttest_ind(a_dist, b_dist, equal_var<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Zscore is </span><span style=color:#5af78e>{</span>zscore<span style=color:#5af78e>:</span><span style=color:#5af78e>0.2f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>, p-value is </span><span style=color:#5af78e>{</span>prob<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e> (two tailed), </span><span style=color:#5af78e>{</span>prob<span style=color:#ff6ac1>/</span><span style=color:#ff9f43>2</span><span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e> (one tailed)&#34;</span>)
</span></span></code></pre></div></div><pre><code>Zscore is -1.89, p-value is 0.059 (two tailed), 0.030 (one tailed)
</code></pre><p>Note here that the p-value by default is using the two-tailed test. We can see these values are almost identical to the ones we computed ourselves&mldr; but they&rsquo;re not exactly the same. Why is this? Well, the ttest_ind (with <code>equal_var=False</code>) is running Welch&rsquo;s t-test. The t-test has degrees-of-freedom which will induce subtle differences with the normal approximation. Additionally, Welsch&rsquo;s t-test is meant for continuous data, we have discrete 0 and 1 options. A better option for discrete data is the Mann-Whitney U statistic.</p><h2 id=mann-whitney-u-test>Mann-Whitney U test</h2><div class=width-74 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> mannwhitneyu
</span></span><span style=display:flex><span>stat, p_value <span style=color:#ff6ac1>=</span> mannwhitneyu(a_dist, b_dist, alternative<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;less&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Mann-Whitney U test for null hypothesis B &lt;= A is </span><span style=color:#5af78e>{</span>p_value<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>)
</span></span></code></pre></div></div><pre><code>Mann-Whitney U test for null hypothesis B &lt;= A is 0.028
</code></pre><p>So you can see that our p-value is low and we can reject the null hypthesis. Noticed too that we have <code>alternative="less"</code>, which is the null hypothesis that we are testing so that we can investigate if B > A.</p><p>Again we can see a super similar answer to what we got before. For cases when we have hundreds of data points, these answers quickly converge, and you can pick the flavour you like.</p><h1 id=a-bayesian-approach>A Bayesian Approach</h1><p>Everything up to now has been standard frequentist hypothesis testing. But we can formulate a model and fit it in A Bayesian approach. For a Bayesian approach, we need to contruct a model of our posterior that includes our prior and our likelihood. <a href=https://cosmiccoding.com.au/tutorials/bayes_lin_reg>For more detail on those, see this example</a>.</p><p><strong>NOTE: Whilst I enjoy Bayesian approaches, for a simple model like this I would say this is vastly overkill for a real world analysis. I include it here simply for fun.</strong></p><h3 id=model-parameters>Model Parameters:</h3><ul><li>$P_A$: Actual probability of conversion for A</li><li>$\delta_P$: Delta probability such that $P_B$ = $P_A$ + $\delta_P$</li></ul><h3 id=model-data>Model Data:</h3><ul><li>$N_A$, $R_A$: number of total visits and conversion ratio for A</li><li>$N_B$, $R_B$: number of total visits and conversion ratio for B</li></ul><p>We will give $P_A$ a flat prior between 0 and 1. And for $\delta_P$, we will also give a flat prior. We might also consider another prior like a half-Cauchy, but I want to keep this as simple as humanely possible. For simplicity, we will also utilise the normal approximation for our Bernoulli distritubion, as working with continuous numbers is easier than discrete. That means our posterior is given by:</p><p>$$ P(\theta|data) = N\left( \frac{P_A - R_A}{\sqrt{R_A(1-R_A)/N_A}} \right) N \left( \frac{P_A + \delta_P - R_B}{\sqrt{R_B(1-R_B)/N_B}} \right) $$</p><p>When we implement it, we work with log probabilities.</p><div class="expanded-code width-92" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_prior</span>(x):
</span></span><span style=display:flex><span>    p, delta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff9f43>0</span> <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff9f43>0</span> <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>+</span> delta <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span> <span style=color:#ff6ac1>&lt;</span> delta <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>0.1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_likelihood</span>(x):
</span></span><span style=display:flex><span>    p, delta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> norm()<span style=color:#ff6ac1>.</span>logpdf((p <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> std_a) <span style=color:#ff6ac1>+</span> norm()<span style=color:#ff6ac1>.</span>logpdf((p <span style=color:#ff6ac1>+</span> delta <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> std_b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_posterior</span>(x):
</span></span><span style=display:flex><span>    prior <span style=color:#ff6ac1>=</span> get_prior(x)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> np<span style=color:#ff6ac1>.</span>isfinite(prior):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> prior <span style=color:#ff6ac1>+</span> get_likelihood(x)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> prior
</span></span></code></pre></div></div><p>So that&rsquo;s our model defined. Let&rsquo;s fit it using <a href=https://emcee.readthedocs.io/en/stable/><code>emcee</code></a>. As a note, this model is simple enough that we could actually do this analytically, but this is a more useful example if don&rsquo;t. This may take a while to run.</p><div class=width-78 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> emcee
</span></span><span style=display:flex><span>ndim <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>2</span>  <span style=color:#78787e># How many parameters we are fitting. This is our dimensionality.</span>
</span></span><span style=display:flex><span>nwalkers <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>30</span>  <span style=color:#78787e># Keep this well above your dimensionality.</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>uniform(low<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, high<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, size<span style=color:#ff6ac1>=</span>(nwalkers, ndim))  <span style=color:#78787e># Start points</span>
</span></span><span style=display:flex><span>sampler <span style=color:#ff6ac1>=</span> emcee<span style=color:#ff6ac1>.</span>EnsembleSampler(nwalkers, ndim, get_posterior)
</span></span><span style=display:flex><span>state <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>run_mcmc(p0, <span style=color:#ff9f43>2000</span>)  <span style=color:#78787e># Tell each walker to take some steps</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chain <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>chain[:, <span style=color:#ff9f43>200</span>:, :]  <span style=color:#78787e># Throw out the first 200 steps</span>
</span></span><span style=display:flex><span>flat_chain <span style=color:#ff6ac1>=</span> chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim))  <span style=color:#78787e># Stack the steps from each walker</span>
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(flat_chain)
</span></span></code></pre></div></div><pre><code>[[0.0660124  0.04519312]
 [0.06044587 0.05760786]
 [0.05904935 0.0586979 ]
 ...
 [0.07143426 0.0553055 ]
 [0.0747643  0.04823904]
 [0.0747643  0.04823904]]
</code></pre><p>Great, so we have samples from the posterior, but this doesn&rsquo;t mean much. Lets throw them into <a href=https://samreay.github.io/ChainConsumer/><code>ChainConsumer</code></a>, a library of mine to digest MCMC samples from model fitting algorithms.</p><div class=width-68 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> chainconsumer <span style=color:#ff6ac1>import</span> ChainConsumer
</span></span><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>[<span style=color:#5af78e>&#34;$P_A$&#34;</span>, <span style=color:#5af78e>&#34;$\delta_P$&#34;</span>], kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot();
</span></span></code></pre></div></div><p><div><figure class=rounded><picture><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_25_1_hu8d47fb4fa9934628cabfdcfbf954a010_105370_1346x0_resize_q90_h2_box_3.webp width=1346 height=1413 type=image/webp><source srcset=/tutorials/abtests/2020-01-12-ABTests_files/2020-01-12-ABTests_25_1.png width=1346 height=1413 type=image/png><img width=1346 height=1413 loading=lazy decoding=async alt=png src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mPMn7vLFAAFRgH97g1QygAAAABJRU5ErkJggg=="></picture></figure></div></p><p>What we&rsquo;re interested in most of all are the constraints on $\delta_P$, which is $\delta_P = 0.037^{+0.021}_{-0.019}$ (this is the 68% confidence level). This means that we rule out $\delta_P=0$ at the $2\sigma$ confidence level (aka 95% confidence level), allowing us to say that B does in indeed produce a statistically significant increase in conversion rate.</p><hr><p>For your convenience, here&rsquo;s the code in one block:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>num_a, num_b <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>550</span>, <span style=color:#ff9f43>450</span>
</span></span><span style=display:flex><span>click_a, click_b <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>48</span>, <span style=color:#ff9f43>56</span>
</span></span><span style=display:flex><span>rate_a, rate_b <span style=color:#ff6ac1>=</span> click_a <span style=color:#ff6ac1>/</span> num_a, click_b <span style=color:#ff6ac1>/</span> num_b
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> matplotlib.pyplot <span style=color:#ff6ac1>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> binom
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Determine the probability of having x click throughs</span>
</span></span><span style=display:flex><span>clicks <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>arange(<span style=color:#ff9f43>20</span>, <span style=color:#ff9f43>80</span>)
</span></span><span style=display:flex><span>prob_a <span style=color:#ff6ac1>=</span> binom(num_a, rate_a)<span style=color:#ff6ac1>.</span>pmf(clicks)
</span></span><span style=display:flex><span>prob_b <span style=color:#ff6ac1>=</span> binom(num_b, rate_b)<span style=color:#ff6ac1>.</span>pmf(clicks)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Make the bar plots.</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>bar(clicks, prob_a, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;A&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>bar(clicks, prob_b, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;B&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>&#34;Num converted&#34;</span>); plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;Probability&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> norm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Where does this come from? See the link above.</span>
</span></span><span style=display:flex><span>std_a <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_a <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> num_a)
</span></span><span style=display:flex><span>std_b <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_b <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> num_b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>click_rate <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>0.2</span>, <span style=color:#ff9f43>200</span>)
</span></span><span style=display:flex><span>prob_a <span style=color:#ff6ac1>=</span> norm(rate_a, std_a)<span style=color:#ff6ac1>.</span>pdf(click_rate)
</span></span><span style=display:flex><span>prob_b <span style=color:#ff6ac1>=</span> norm(rate_b, std_b)<span style=color:#ff6ac1>.</span>pdf(click_rate)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Make the bar plots.</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(click_rate, prob_a, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;A&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(click_rate, prob_b, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;B&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>xlabel(<span style=color:#5af78e>&#34;Conversion rate&#34;</span>); plt<span style=color:#ff6ac1>.</span>ylabel(<span style=color:#5af78e>&#34;Probability&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#78787e># The z-score is really all we need if we want a number</span>
</span></span><span style=display:flex><span>z_score <span style=color:#ff6ac1>=</span> (rate_b <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;z-score is </span><span style=color:#5af78e>{</span>z_score<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>, with p-value </span><span style=color:#5af78e>{</span>norm()<span style=color:#ff6ac1>.</span>sf(z_score)<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># But I want a plot as well</span>
</span></span><span style=display:flex><span>p <span style=color:#ff6ac1>=</span> norm(rate_b <span style=color:#ff6ac1>-</span> rate_a, np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>))
</span></span><span style=display:flex><span>x <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.05</span>, <span style=color:#ff9f43>0.15</span>, <span style=color:#ff9f43>1000</span>)
</span></span><span style=display:flex><span>y <span style=color:#ff6ac1>=</span> p<span style=color:#ff6ac1>.</span>pdf(x)
</span></span><span style=display:flex><span>area_under_curve <span style=color:#ff6ac1>=</span> p<span style=color:#ff6ac1>.</span>sf(<span style=color:#ff9f43>0</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>plot(x, y, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;PDF&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>fill_between(x, <span style=color:#ff9f43>0</span>, y, where<span style=color:#ff6ac1>=</span>x<span style=color:#ff6ac1>&gt;</span><span style=color:#ff9f43>0</span>, label<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;Prob(b&gt;a)&#34;</span>, alpha<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.3</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff6ac1>.</span>annotate(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Area=</span><span style=color:#5af78e>{</span>area_under_curve<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>, (<span style=color:#ff9f43>0.02</span>, <span style=color:#ff9f43>5</span>))
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_confidence_ab_test</span>(click_a, num_a, click_b, num_b):
</span></span><span style=display:flex><span>    rate_a <span style=color:#ff6ac1>=</span> click_a <span style=color:#ff6ac1>/</span> num_a
</span></span><span style=display:flex><span>    rate_b <span style=color:#ff6ac1>=</span> click_b <span style=color:#ff6ac1>/</span> num_b
</span></span><span style=display:flex><span>    std_a <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_a <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> num_a)
</span></span><span style=display:flex><span>    std_b <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>sqrt(rate_b <span style=color:#ff6ac1>*</span> (<span style=color:#ff9f43>1</span> <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> num_b)
</span></span><span style=display:flex><span>    z_score <span style=color:#ff6ac1>=</span> (rate_b <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> np<span style=color:#ff6ac1>.</span>sqrt(std_a<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span> <span style=color:#ff6ac1>+</span> std_b<span style=color:#ff6ac1>**</span><span style=color:#ff9f43>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> norm<span style=color:#ff6ac1>.</span>cdf(z_score)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(get_confidence_ab_test(click_a, num_a, click_b, num_b))
</span></span><span style=display:flex><span><span style=color:#78787e># Draw 10000 samples of possible rates for a and b</span>
</span></span><span style=display:flex><span>n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>10000</span>
</span></span><span style=display:flex><span>rates_a <span style=color:#ff6ac1>=</span> norm(rate_a, std_a)<span style=color:#ff6ac1>.</span>rvs(n)
</span></span><span style=display:flex><span>rates_b <span style=color:#ff6ac1>=</span> norm(rate_b, std_b)<span style=color:#ff6ac1>.</span>rvs(n)
</span></span><span style=display:flex><span>b_better <span style=color:#ff6ac1>=</span> (rates_b <span style=color:#ff6ac1>&gt;</span> rates_a)<span style=color:#ff6ac1>.</span>mean()
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;B is better than A </span><span style=color:#5af78e>{</span>b_better<span style=color:#5af78e>:</span><span style=color:#5af78e>0.1%</span><span style=color:#5af78e>}</span><span style=color:#5af78e> of the time&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> ttest_ind
</span></span><span style=display:flex><span>a_dist <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(num_a)
</span></span><span style=display:flex><span>a_dist[:click_a] <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>1</span>
</span></span><span style=display:flex><span>b_dist <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(num_b)
</span></span><span style=display:flex><span>b_dist[:click_b] <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>1</span>
</span></span><span style=display:flex><span>zscore, prob <span style=color:#ff6ac1>=</span> ttest_ind(a_dist, b_dist, equal_var<span style=color:#ff6ac1>=</span><span style=color:#ff6ac1>False</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Zscore is </span><span style=color:#5af78e>{</span>zscore<span style=color:#5af78e>:</span><span style=color:#5af78e>0.2f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>, p-value is </span><span style=color:#5af78e>{</span>prob<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e> (two tailed), </span><span style=color:#5af78e>{</span>prob<span style=color:#ff6ac1>/</span><span style=color:#ff9f43>2</span><span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e> (one tailed)&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> scipy.stats <span style=color:#ff6ac1>import</span> mannwhitneyu
</span></span><span style=display:flex><span>stat, p_value <span style=color:#ff6ac1>=</span> mannwhitneyu(a_dist, b_dist, alternative<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;less&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(<span style=color:#5af78e>f</span><span style=color:#5af78e>&#34;Mann-Whitney U test for null hypothesis B &lt;= A is </span><span style=color:#5af78e>{</span>p_value<span style=color:#5af78e>:</span><span style=color:#5af78e>0.3f</span><span style=color:#5af78e>}</span><span style=color:#5af78e>&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_prior</span>(x):
</span></span><span style=display:flex><span>    p, delta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff9f43>0</span> <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff9f43>0</span> <span style=color:#ff6ac1>&lt;</span> p <span style=color:#ff6ac1>+</span> delta <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> <span style=color:#ff6ac1>not</span> <span style=color:#ff6ac1>-</span><span style=color:#ff9f43>0.1</span> <span style=color:#ff6ac1>&lt;</span> delta <span style=color:#ff6ac1>&lt;</span> <span style=color:#ff9f43>0.1</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> <span style=color:#ff6ac1>-</span>np<span style=color:#ff6ac1>.</span>inf
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_likelihood</span>(x):
</span></span><span style=display:flex><span>    p, delta <span style=color:#ff6ac1>=</span> x
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> norm()<span style=color:#ff6ac1>.</span>logpdf((p <span style=color:#ff6ac1>-</span> rate_a) <span style=color:#ff6ac1>/</span> std_a) <span style=color:#ff6ac1>+</span> norm()<span style=color:#ff6ac1>.</span>logpdf((p <span style=color:#ff6ac1>+</span> delta <span style=color:#ff6ac1>-</span> rate_b) <span style=color:#ff6ac1>/</span> std_b)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_posterior</span>(x):
</span></span><span style=display:flex><span>    prior <span style=color:#ff6ac1>=</span> get_prior(x)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>if</span> np<span style=color:#ff6ac1>.</span>isfinite(prior):
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>return</span> prior <span style=color:#ff6ac1>+</span> get_likelihood(x)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> prior
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> emcee
</span></span><span style=display:flex><span>ndim <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>2</span>  <span style=color:#78787e># How many parameters we are fitting. This is our dimensionality.</span>
</span></span><span style=display:flex><span>nwalkers <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>30</span>  <span style=color:#78787e># Keep this well above your dimensionality.</span>
</span></span><span style=display:flex><span>p0 <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>uniform(low<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0</span>, high<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>0.1</span>, size<span style=color:#ff6ac1>=</span>(nwalkers, ndim))  <span style=color:#78787e># Start points</span>
</span></span><span style=display:flex><span>sampler <span style=color:#ff6ac1>=</span> emcee<span style=color:#ff6ac1>.</span>EnsembleSampler(nwalkers, ndim, get_posterior)
</span></span><span style=display:flex><span>state <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>run_mcmc(p0, <span style=color:#ff9f43>2000</span>)  <span style=color:#78787e># Tell each walker to take some steps</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chain <span style=color:#ff6ac1>=</span> sampler<span style=color:#ff6ac1>.</span>chain[:, <span style=color:#ff9f43>200</span>:, :]  <span style=color:#78787e># Throw out the first 200 steps</span>
</span></span><span style=display:flex><span>flat_chain <span style=color:#ff6ac1>=</span> chain<span style=color:#ff6ac1>.</span>reshape((<span style=color:#ff6ac1>-</span><span style=color:#ff9f43>1</span>, ndim))  <span style=color:#78787e># Stack the steps from each walker</span>
</span></span><span style=display:flex><span><span style=color:#ff5c57>print</span>(flat_chain)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> chainconsumer <span style=color:#ff6ac1>import</span> ChainConsumer
</span></span><span style=display:flex><span>c <span style=color:#ff6ac1>=</span> ChainConsumer()
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>add_chain(flat_chain, parameters<span style=color:#ff6ac1>=</span>[<span style=color:#5af78e>&#34;$P_A$&#34;</span>, <span style=color:#5af78e>&#34;$\delta_P$&#34;</span>], kde<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1.0</span>)
</span></span><span style=display:flex><span>c<span style=color:#ff6ac1>.</span>plotter<span style=color:#ff6ac1>.</span>plot();
</span></span></code></pre></div><div class="relative max-w-xl mx-auto my-20"><div class="fancy_card horizontal"><div class=card_translator><div class="card_rotator tiny_rot card_layer"><div class="card_layer newsletter p-2"><div class="newsletter-inner h-full"><div class="relative h-full sib-form-container" id=sib-form-container><div class="mb-6 lg:mb-12 text-center"><h3 class="text-main-200 mb-2 lg:mb-8">Stay in the loop!</h3><p class="text-main-100 text-lg text-opacity-70">For new releases, exclusive giveaways, and reviews.</p></div><form action="https://Cosmiccoding.us5.list-manage.com/subscribe/post?u=aebe5de1d2e40dccb3aeca491&id=3987dd4a1f" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate w-full" target=_blank novalidate><div><input type=email class="w-full appearance-none bg-main-600 mb-4 border border-main-600 bg-opacity-5 focus:border-main-300 rounded-sm px-4 py-3 text-main-100 placeholder-main-100 required" placeholder="Your best email…" aria-label="Your best email…" name=EMAIL required data-required=true id=EMAIL><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_aebe5de1d2e40dccb3aeca491_3987dd4a1f tabindex=-1></div><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class="button btn bg-main-600 hover:bg-main-400 shadow w-full"></div><p id=mce-error-response style=display:none class="text-center mt-2 opacity-50 text-main-200">There was a problem, please try again.</p><p id=mce-success-response style=display:none class="text-center mt-2 opacity-50 text-main-200">Thanks mate, won't let ya down.</p></form></div></div></div><div class="card_layer card_effect card_soft_glare" style=pointer-events:none></div></div></div></div></div></div><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div><script language=javascript type=text/javascript src=https://cosmiccoding.com.au/js/main.min.11673d10a962fb5205229607e62ea1d23424d35dad33db7bfe2a09a63d5409fa.js></script>
<script async defer src="https://www.googletagmanager.com/gtag/js?id=G-GRX6QE03YR"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GRX6QE03YR")</script></div></body></html>