<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Simple Multiprocessing in Python - Samuel Hinton</title><link rel=stylesheet href="https://cosmiccoding.com.au/css/main.min.7fbf65bef988e0cecd6d148a59756085deed3c480729d260d0a30b282b1d7da8.css" integrity="sha256-f79lvvmI4M7NbRSKWXVghd7tPEgHKdJg0KMLKCsdfag="><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel="shortcut icon" href=https://cosmiccoding.com.au/img/favicon.png type=image/x-icon></head><meta name=description content="Comparing inbuilt solutions to a range of external libraries."><meta name=robots content="noodp"><link rel=canonical href=https://cosmiccoding.com.au/tutorials/multiprocessing/><meta name=twitter:card content="summary"><meta name=twitter:title content="Simple Multiprocessing in Python"><meta name=twitter:description content="Comparing inbuilt solutions to a range of external libraries."><meta property="og:title" content="Simple Multiprocessing in Python"><meta property="og:description" content="Comparing inbuilt solutions to a range of external libraries."><meta property="og:type" content="article"><meta property="og:url" content="https://cosmiccoding.com.au/tutorials/multiprocessing/"><meta property="article:section" content="tutorials"><meta property="article:published_time" content="2021-05-14T00:00:00+00:00"><meta property="article:modified_time" content="2021-05-14T00:00:00+00:00"><meta property="article:section" content="tutorial"><meta property="article:published_time" content="2021-05-14 00:00:00 +0000 UTC"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Simple Multiprocessing in Python","genre":"tutorial","url":"https:\/\/cosmiccoding.com.au\/tutorials\/multiprocessing\/","datePublished":"2021-05-14 00:00:00 \u002b0000 UTC","description":"Comparing inbuilt solutions to a range of external libraries.","author":{"@type":"Person","name":""}}</script><body><div class="flex flex-col min-h-screen overflow-hidden"><header class="absolute w-full z-30"><div class="max-w-6xl mx-auto px-4 sm:px-6"><div class="flex items-center justify-between h-20"><div class="flex-shrink-0 mr-4"><a class=block href=/ aria-label="Samuel Hinton"><h2 class=logo>SRH</h2></a></div><nav class="hidden md:flex md:flex-grow"><ul class="flex flex-grow justify-end flex-wrap items-center"><li><a href=/#books class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Books</a></li><li><a href=/reviews class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Reviews</a></li><li><a href=/tutorials class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Tutorials</a></li><li><a href=/blogs class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Blog</a></li><li><a href=/#courses class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="text-gray-300 hover:text-gray-200 px-4 py-2 flex items-center transition duration-150 ease-in-out">CV</a></li></ul></nav><div class=md:hidden x-data="{ expanded: false }"><button class=hamburger :class="{ 'active': expanded }" @click.stop="expanded = !expanded" aria-controls=mobile-nav :aria-expanded=expanded>
<span class=sr-only>Menu</span><svg class="w-6 h-6 fill-current text-gray-300 hover:text-gray-200 transition duration-150 ease-in-out" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><rect y="4" width="24" height="2" rx="1"/><rect y="11" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg></button><nav id=mobile-nav class="absolute top-full z-20 left-0 w-full px-4 sm:px-6 overflow-hidden transition-all duration-300 ease-in-out" x-ref=mobileNav :style="expanded ? 'max-height: ' + $refs.mobileNav.scrollHeight + 'px; opacity: 1' : 'max-height: 0; opacity: .8'" @click.away="expanded = false" @keydown.escape.window="expanded = false" x-cloak><ul class="bg-gray-800 px-4 py-2"><li><a href=/#books class="flex text-gray-300 hover:text-gray-200 py-2">Books</a></li><li><a href=/reviews class="flex text-gray-300 hover:text-gray-200 py-2">Reviews</a></li><li><a href=/tutorials class="flex text-gray-300 hover:text-gray-200 py-2">Tutorials</a></li><li><a href=/blogs class="flex text-gray-300 hover:text-gray-200 py-2">Blog</a></li><li><a href=/#courses class="flex text-gray-300 hover:text-gray-200 py-2">Courses</a></li><li><a href=/static/resume/HintonCV.pdf class="flex text-gray-300 hover:text-gray-200 py-2">CV</a></li></ul></nav></div></div></div></header><div class=flex-grow><div id=post-container class="content content-wider blog-post relative"><div class="section-header blog"><h1 class=title>Simple Multiprocessing in Python</h1><p>6th May 2021</p><p>Comparing inbuilt solutions to a range of external libraries.</p></div><div><ul class="grid gap-6 w-full md:grid-cols-2" style=list-style:none;padding-left:0><li><input type=radio id=show-code name=code-toggle value=show-code class="hidden peer" onchange=clickCheckbox(this) required checked>
<label for=show-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Show me everything!</div><div class="w-full text-center text-sm">Oh yeah, coding time.</div></div></label></li><li><input type=radio id=hide-code name=code-toggle value=hide-code class="hidden peer" onchange=clickCheckbox(this)>
<label for=hide-code class="inline-flex justify-between items-center p-5 w-full text-gray-500 bg-gray-800 rounded-lg border border-gray-200 cursor-pointer peer-checked:border-2 peer-checked:border-main-300 peer-checked:text-white peer-checked:bg-gray-700 hover:text-gray-200 hover:bg-gray-700"><div class="block w-full"><div class="w-full text-center text-lg font-semibold">Just the plots</div><div class="w-full text-center text-sm">Code is nasty.</div></div></label></li></ul></div><script>function clickCheckbox(e){e.id=="show-code"?document.getElementById("post-container").classList.remove("hide-code"):document.getElementById("post-container").classList.add("hide-code")}</script><p>In this short writeup I&rsquo;ll give examples of various multiprocessing libraries, how to use them with minimal setup, and what their strengths are.</p><p>If you want a TL;DR - I recommend trying out <code>loky</code> for single machine tasks, check out Ray for larger tasks.</p><div class="reduced-code width-46" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># Loky, great for single machine parallelism </span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> loky <span style=color:#ff6ac1>import</span> get_reusable_executor
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor()
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(fn, jobs))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Ray, great for distributing over machines</span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> ray
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>init()
</span></span><span style=display:flex><span>workfn <span style=color:#ff6ac1>=</span> ray<span style=color:#ff6ac1>.</span>remote(fn)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> [workfn<span style=color:#ff6ac1>.</span>remote(job) <span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs]
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>get(results)
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>shutdown();
</span></span></code></pre></div></div><h1 id=cpu-bound-tasks>CPU bound tasks</h1><p>Most of the jobs we (I) want to execute are CPU bound. All I&rsquo;m doing is crunching some numbers, retraining models, over and over, and I want to spend the least amount of time twiddling my thumbs.</p><p>So let&rsquo;s simulate a common task, which is evaluating some arbitrarily slow function over and over again. Here I create a function which takes some array of parameters as input, and produces a single number as output. And then I create 512 different vectors in parameter space, and want to evaluate the function of each of the 512 sets of parameters.</p><div class=width-65 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>slow_fn</span>(args):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; Simulated an optimisation problem with args coming in
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    and function value being output &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>10000</span>
</span></span><span style=display:flex><span>    y <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>range</span>(n):
</span></span><span style=display:flex><span>        j <span style=color:#ff6ac1>=</span> j <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>for</span> i, p <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>enumerate</span>(args):
</span></span><span style=display:flex><span>            y <span style=color:#ff6ac1>+=</span> j <span style=color:#ff6ac1>*</span> (p <span style=color:#ff6ac1>**</span> (i <span style=color:#ff6ac1>+</span> <span style=color:#ff9f43>1</span>))
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> y <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_jobs</span>(num_jobs<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>512</span>, num_args<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; Simulated sampling our parameter space multiple times &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> [j <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>random((num_jobs, num_args))]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>jobs <span style=color:#ff6ac1>=</span> get_jobs()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Check out this single core performance</span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs:
</span></span><span style=display:flex><span>    slow_fn(job)
</span></span></code></pre></div></div><p>On my struggling laptop, these 512 jobs took <code>20.30s</code> to complete when running the functions in serial.</p><h2 id=pythons-concurrentfutures>Pythons Concurrent.Futures</h2><p>It&rsquo;s best to start with some of the provided options in the standard library.</p><div class=width-62 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> concurrent.futures <span style=color:#ff6ac1>import</span> ProcessPoolExecutor
</span></span><span style=display:flex><span><span style=color:#ff6ac1>with</span> ProcessPoolExecutor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>) <span style=color:#ff6ac1>as</span> executor:
</span></span><span style=display:flex><span>    results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span></code></pre></div></div><p>With four workers and a chunksize of 16, this took me <code>6.47s</code>. If we disable chunking (which is a bad idea for small functions like this when you have a lot of them), it takes <code>6.57s</code>. Not much of a difference, but then again, 512 jobs isn&rsquo;t a particularly large number. Like effectively all of the multiprocessing options provided in the standard library, this method relies on process forking and <strong>will not work inside a Jupyter notebook,</strong> instead you&rsquo;ll need to throw the code into a python file and run it the good old <code>python yourfile.py</code> way.</p><h2 id=loky>Loky</h2><p><a href=https://github.com/joblib/loky>Loky</a> (from the smart cookies at joblib) is a suped up version of the Executor pool above that features reusable executors and code serialisation.</p><div class="reduced-code width-58" markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> loky <span style=color:#ff6ac1>import</span> get_reusable_executor
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span></code></pre></div></div><p>This ran in <code>6.31s</code> on my machine, the fastest yet.</p><p>Loky has the benefit of distributing work by pickling the code you are trying to run and the arguments (using <code>cloudpickle</code>). This means it is much more flexible, and this method <strong>will</strong> run inside a Jupter notebook. Hell, it should run just about anywhere.</p><p>The benefit you get from this freedom might start to be outweighed by the fact you are adding overhead (serialising the code) to your workload, but often this can be kept to a bare minimum. And in our case, the overhead of pickling the code was less than the overhead of the process setup used by the inbuilt <code>concurrent.futures</code> module, so we ran things faster.</p><p>Cloudpickle will not serialise code outside of the local module, so if you want to lower the pickling overhead, just extract the function to another file (and if you&rsquo;re shipping the code off to an external machine, make sure it has said file too).</p><p>To try and make sure this point is clear, the function <code>slow_fn</code> is defined within this file. Cloudpickle will turn all its code into bytes. If I move the function into <code>foo.py</code>, cloudpickle would only save out &ldquo;Call <code>foo.slow_fn</code>&rdquo; instead of the code itself. Reduce overheads, but add requirements for code to be in the right place. This overhead should be minimial unless you have a truly mammoth single function you&rsquo;re exporting. Still, your choice!</p><h2 id=mpi4py>MPI4PY</h2><p><a href=https://en.wikipedia.org/wiki/Message_Passing_Interface>MPI</a> (Mesasge Parsing Interface) is a super handy way of spreading computational load not just around on one CPU, but across multiple CPU. <a href=https://mpi4py.readthedocs.io/en/stable/>mpi4py</a> is a python implementation making our lives easier. It is used commonly in super computers, where you use systems like PBS, SGE, Torque, or Slurm to request many CPUs that might be located on completely different nodes. If you are only looking at once CPU and have no plans to move off it, there are simpler methods than MPI. If you did want to use MPI, you would do something like this:</p><div class=width-62 markdown=1><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff6ac1>from</span> mpi4py.futures <span style=color:#ff6ac1>import</span> MPIPoolExecutor
</span></span><span style=display:flex><span><span style=color:#ff6ac1>with</span> MPIPoolExecutor() <span style=color:#ff6ac1>as</span> executor:
</span></span><span style=display:flex><span>    results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span></code></pre></div></div><p>And you would execute the code not using <code>python yourfile.py</code>, but instead use <code>mpirun</code> or <code>mpiexec</code> and tell it how many cores you have. Like so:</p><div class="expanded-code width-396" markdown=1><p><code>mpiexec -n 8 python =-m mpi4py.futures yourfile.py</code></p><p>I&rsquo;ve used MPI to distribute parallel processing loads which require minimal cross-talk. To go back to my astrophysics days, if you have 10k images of the night sky and need to process all of them, this is a great way of easily shipping the processing off to whatever CPU you can get your hands on in the supercomputers you have access to.</p><p>Just keep in mind - the message parsing part is the expensive part. Minimise the network overhead to maximise your processing speed. For local CPU tasks, this will give you the same speed as <code>concurrent.futures</code>.</p><h2 id=ray>Ray</h2><p>Want to go a lot fancier and start bringing in some big guns? <a href=https://docs.ray.io/en/master/index.html>Ray</a> is also great for distributing your tasks over more than one CPU, and the setup for it is also very minimal. That being said, don&rsquo;t think Ray is a simple piece of code, there is a LOT in it, and it can do a lot of things (dashboards, autoscaling, model serving, and a whole bunch more).</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> ray
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>init()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>workfn <span style=color:#ff6ac1>=</span> ray<span style=color:#ff6ac1>.</span>remote(slow_fn)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> [workfn<span style=color:#ff6ac1>.</span>remote(job) <span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs]
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>get(results)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>shutdown();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-589&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><p>Because this is also shipping your code elsewhere, it should run no issues in a Jupyter Notebook. Not that you&rsquo;d normally want to do that, generally you&rsquo;d put the ray server on a compute node somewhere, and then just connect to it, farming your jobs out.</p><p>Anyway, the principle is straightforward. I set up a server, tell it that a specific function should be executed remotely (which in this case, is still my machine, but using all my cores now), and then send it off.</p><p>All up, this took <code>16s</code> to run, but of those, <code>4.89s</code> was on actual computation, and the other <code>12s</code> was setting up and shutting down the server.</p><p>Pretty impressive. Add onto that the fact that Ray has a ton of integrations (including some great <a href=https://docs.ray.io/en/latest/tune/api_docs/suggestion.html><code>HyperOptSearch</code></a>) and I&rsquo;m a fan.</p><h2 id=dask>Dask</h2><p>If you liked the sound of Ray, you&rsquo;ll probably like the sound of <a href=https://dask.org/><code>Dask</code></a>. Similar principle with workers and a controlling node. More focus on numerical computation, and it sits behind a lot of other distributed software (like <code>Prefect</code> as a single example). Note that if you&rsquo;re on windows, this may give you some issues, and for me <a href=https://github.com/dask/community/issues/150>versioning mismatches in the conda release</a> made this a painful install, but hopefully this was just me getting unlucky with updating to a bugged version, and it doesn&rsquo;t affect anyone else.</p><p>Once you have it installed, the rest is easy. Again, super basic usage only - making <code>Client()</code> set up a local client in the background isn&rsquo;t something you&rsquo;d productionise!</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> dask.distributed <span style=color:#ff6ac1>import</span> Client
</span></span><span style=display:flex><span>client <span style=color:#ff6ac1>=</span> Client()
</span></span><span style=display:flex><span><span style=color:#78787e># Send off jobs</span>
</span></span><span style=display:flex><span>futures <span style=color:#ff6ac1>=</span> client<span style=color:#ff6ac1>.</span>map(slow_fn, jobs)
</span></span><span style=display:flex><span><span style=color:#78787e># Get their outputs</span>
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> client<span style=color:#ff6ac1>.</span>gather(futures)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-343&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><p>All up this took <code>7.4s</code>, with <code>5.8s</code> spent on compute and the rest launching the local cluster in the background.</p><h2 id=p_tqdm-aka-pathos--tqdm>p_tqdm (aka Pathos + tqdm)</h2><p><a href=https://github.com/tqdm/tqdm>tqdm</a> is not an acronym, but it is a progress bar. <a href=https://pathos.readthedocs.io/en/latest/pathos.html>Pathos</a> is a framework for heterogeneous computing. <a href=https://github.com/swansonk14/p_tqdm>p_tqdm</a> is a library where @swansonk14 has stuck them both together. So think more a competitor to Ray than to Loky.</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> p_tqdm <span style=color:#ff6ac1>import</span> p_map
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> p_map(slow_fn, jobs);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-397&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><pre><code>100%|██████████| 512/512 [00:05&lt;00:00, 96.89it/s] 
</code></pre><p>I was surprised this ran faster than both <code>concurrent.futures</code> and <code>loky</code>, it came in at only <code>5.38s</code>. And you even get a progress bar so that you know things are still running and progressing smoothly. Obviously in my case, I don&rsquo;t really need it, but if you have a job which will take 10 hours to run, it would be great to know that its slowly chewing through the tasks and not actually hanging.</p><p>And as you saw, its ridiculously easy to set up. If you want to see the other things you can do <code>map</code> (blocking) vs <code>imap</code> (non-blocking) vs <code>amap</code> (async) then jump into their documentation linked above.</p><p>If you don&rsquo;t care at all about the progress bar, to get stock pathos multiprocessing working, this will work:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> pathos.multiprocessing <span style=color:#ff6ac1>import</span> ProcessPool
</span></span><span style=display:flex><span>pool <span style=color:#ff6ac1>=</span> ProcessPool()
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> pool<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-267&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><h1 id=memory-blocking>Memory Blocking</h1><p>A common issue with attempts at multiprocessing on a single physical CPU is that there are many things which can bottleneck CPU execution. On many machines, memory management is done at the kernel level, which means that any <code>malloc</code> calls cannot be done in parallel.</p><p>First, consider our original <code>slow_fn</code> - it took 20 seconds to run in serial, and around 5s to run over 4 cores. This is the ideal result.</p><p>Now consider a vectorised version of our <code>slow_fn</code>, like so:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>slow_fn_malloc</span>(args):
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>100000</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>1</span>, n)
</span></span><span style=display:flex><span>    y <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(n)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> i, p <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>enumerate</span>(args):
</span></span><span style=display:flex><span>        y <span style=color:#ff6ac1>+=</span> x <span style=color:#ff6ac1>*</span> (p <span style=color:#ff6ac1>**</span> (i <span style=color:#ff6ac1>+</span> <span style=color:#ff9f43>1</span>))
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> y<span style=color:#ff6ac1>.</span>sum() <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs:
</span></span><span style=display:flex><span>    slow_fn_malloc(job)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-177&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><p>Now, by all accounts, this function is <em>better</em>. Running this took <code>58ms</code>. From 20 seconds down to a twentieth of a second&mldr; Vectorisation is great.</p><p>Let me increase the number of jobs, now that we&rsquo;re burning through jobs so quickly. Oh, I&rsquo;ll also make <code>n</code> ten times larger, to increase the numerical precision of our function.</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_many_jobs</span>(num_jobs<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4096</span>, num_args<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> [j <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>random((num_jobs, num_args))]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>many_jobs <span style=color:#ff6ac1>=</span> get_many_jobs()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;reduced-code width-22&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><p>And timing it we have:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>%%</span>time
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> many_jobs:
</span></span><span style=display:flex><span>    slow_fn_malloc(job)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-264&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span></code></pre></div><pre><code>Wall time: 3.56 s
</code></pre><p>So with even more jobs, and an increase in <code>n</code>, this now takes <code>3.56s</code> to take. Still, very impressive considering this is all on one core now. So what happens if we try to ship it out to multiple cores? Any of the above libraries would work, I&rsquo;ll just use <code>loky</code>:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>%%</span>time
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn_malloc, many_jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span></code></pre></div><pre><code>Wall time: 3.54 s
</code></pre><p>Wait, <code>3.54s</code>&mldr; it didn&rsquo;t improve at all!</p><p>The reason is fairly simple. In <code>slow_fn_malloc</code> the time is being taken creating the arrays, not adding them up. And because creating the arrays requires assigning memory, and thus on many operating systems (like macOS, Windows, and non-compute linux distros) is not parallelised, it doesn&rsquo;t matter how many CPU cores you have, you&rsquo;re just going to be waiting on memory.</p><p>Just thought I&rsquo;d bring that up, in case you&rsquo;re trying to debug why your execution time isn&rsquo;t scaling like how you want - network, disc, and memory are the three most common bottlenecks that get in the way.</p><p>Anyway, hope this short example on how to use a bunch of different multiprocessing libraries is useful!</p><hr><p>For your convenience, here&rsquo;s the code in one block:</p><div class=highlight><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#78787e># Loky, great for single machine parallelism </span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> loky <span style=color:#ff6ac1>import</span> get_reusable_executor
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor()
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(fn, jobs))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Ray, great for distributing over machines</span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> ray
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>init()
</span></span><span style=display:flex><span>workfn <span style=color:#ff6ac1>=</span> ray<span style=color:#ff6ac1>.</span>remote(fn)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> [workfn<span style=color:#ff6ac1>.</span>remote(job) <span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs]
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>get(results)
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>shutdown();
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> numpy <span style=color:#ff6ac1>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>slow_fn</span>(args):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; Simulated an optimisation problem with args coming in
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    and function value being output &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>10000</span>
</span></span><span style=display:flex><span>    y <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>0</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>range</span>(n):
</span></span><span style=display:flex><span>        j <span style=color:#ff6ac1>=</span> j <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>        <span style=color:#ff6ac1>for</span> i, p <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>enumerate</span>(args):
</span></span><span style=display:flex><span>            y <span style=color:#ff6ac1>+=</span> j <span style=color:#ff6ac1>*</span> (p <span style=color:#ff6ac1>**</span> (i <span style=color:#ff6ac1>+</span> <span style=color:#ff9f43>1</span>))
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> y <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_jobs</span>(num_jobs<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>512</span>, num_args<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#5af78e>&#34;&#34;&#34; Simulated sampling our parameter space multiple times &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> [j <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>random((num_jobs, num_args))]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>jobs <span style=color:#ff6ac1>=</span> get_jobs()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#78787e># Check out this single core performance</span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs:
</span></span><span style=display:flex><span>    slow_fn(job)
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> concurrent.futures <span style=color:#ff6ac1>import</span> ProcessPoolExecutor
</span></span><span style=display:flex><span><span style=color:#ff6ac1>with</span> ProcessPoolExecutor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>) <span style=color:#ff6ac1>as</span> executor:
</span></span><span style=display:flex><span>    results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> loky <span style=color:#ff6ac1>import</span> get_reusable_executor
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> mpi4py.futures <span style=color:#ff6ac1>import</span> MPIPoolExecutor
</span></span><span style=display:flex><span><span style=color:#ff6ac1>with</span> MPIPoolExecutor() <span style=color:#ff6ac1>as</span> executor:
</span></span><span style=display:flex><span>    results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>import</span> ray
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>init()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>workfn <span style=color:#ff6ac1>=</span> ray<span style=color:#ff6ac1>.</span>remote(slow_fn)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> [workfn<span style=color:#ff6ac1>.</span>remote(job) <span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs]
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>get(results)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ray<span style=color:#ff6ac1>.</span>shutdown();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-589&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> dask.distributed <span style=color:#ff6ac1>import</span> Client
</span></span><span style=display:flex><span>client <span style=color:#ff6ac1>=</span> Client()
</span></span><span style=display:flex><span><span style=color:#78787e># Send off jobs</span>
</span></span><span style=display:flex><span>futures <span style=color:#ff6ac1>=</span> client<span style=color:#ff6ac1>.</span>map(slow_fn, jobs)
</span></span><span style=display:flex><span><span style=color:#78787e># Get their outputs</span>
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> client<span style=color:#ff6ac1>.</span>gather(futures)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-343&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> p_tqdm <span style=color:#ff6ac1>import</span> p_map
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> p_map(slow_fn, jobs);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-397&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>from</span> pathos.multiprocessing <span style=color:#ff6ac1>import</span> ProcessPool
</span></span><span style=display:flex><span>pool <span style=color:#ff6ac1>=</span> ProcessPool()
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> pool<span style=color:#ff6ac1>.</span>map(slow_fn, jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-267&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>slow_fn_malloc</span>(args):
</span></span><span style=display:flex><span>    n <span style=color:#ff6ac1>=</span> <span style=color:#ff9f43>100000</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>linspace(<span style=color:#ff9f43>0</span>, <span style=color:#ff9f43>1</span>, n)
</span></span><span style=display:flex><span>    y <span style=color:#ff6ac1>=</span> np<span style=color:#ff6ac1>.</span>zeros(n)
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>for</span> i, p <span style=color:#ff6ac1>in</span> <span style=color:#ff5c57>enumerate</span>(args):
</span></span><span style=display:flex><span>        y <span style=color:#ff6ac1>+=</span> x <span style=color:#ff6ac1>*</span> (p <span style=color:#ff6ac1>**</span> (i <span style=color:#ff6ac1>+</span> <span style=color:#ff9f43>1</span>))
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> y<span style=color:#ff6ac1>.</span>sum() <span style=color:#ff6ac1>/</span> n
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> jobs:
</span></span><span style=display:flex><span>    slow_fn_malloc(job)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-177&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>def</span> <span style=color:#57c7ff>get_many_jobs</span>(num_jobs<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4096</span>, num_args<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#ff6ac1>return</span> [j <span style=color:#ff6ac1>for</span> j <span style=color:#ff6ac1>in</span> np<span style=color:#ff6ac1>.</span>random<span style=color:#ff6ac1>.</span>random((num_jobs, num_args))]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>many_jobs <span style=color:#ff6ac1>=</span> get_many_jobs()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;reduced-code width-22&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>%%</span>time
</span></span><span style=display:flex><span><span style=color:#ff6ac1>for</span> job <span style=color:#ff6ac1>in</span> many_jobs:
</span></span><span style=display:flex><span>    slow_fn_malloc(job)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;</span>div class<span style=color:#ff6ac1>=</span><span style=color:#5af78e>&#34;expanded-code width-264&#34;</span> markdown<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>1</span><span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>&lt;/</span>div<span style=color:#ff6ac1>&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff6ac1>%%</span>time
</span></span><span style=display:flex><span>executor <span style=color:#ff6ac1>=</span> get_reusable_executor(max_workers<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>4</span>)
</span></span><span style=display:flex><span>results <span style=color:#ff6ac1>=</span> <span style=color:#ff5c57>list</span>(executor<span style=color:#ff6ac1>.</span>map(slow_fn_malloc, many_jobs, chunksize<span style=color:#ff6ac1>=</span><span style=color:#ff9f43>16</span>));
</span></span></code></pre></div><div class="relative max-w-xl mx-auto my-20"><div class="fancy_card horizontal"><div class=card_translator><div class="card_rotator tiny_rot card_layer"><div class="card_layer newsletter p-2"><div class="newsletter-inner h-full"><div class="relative h-full sib-form-container" id=sib-form-container><div class="mb-6 lg:mb-12 text-center"><h3 class="text-main-200 mb-2 lg:mb-8">Stay in the loop!</h3><p class="text-main-100 text-lg text-opacity-70">For new releases, exclusive giveaways, and reviews.</p></div><form action="https://Cosmiccoding.us5.list-manage.com/subscribe/post?u=aebe5de1d2e40dccb3aeca491&id=3987dd4a1f" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate w-full" target=_blank novalidate><div><input type=email class="w-full appearance-none bg-main-600 mb-4 border border-main-600 bg-opacity-5 focus:border-main-300 rounded-sm px-4 py-3 text-main-100 placeholder-main-100 required" placeholder="Your best email…" aria-label="Your best email…" name=EMAIL required data-required=true id=EMAIL><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_aebe5de1d2e40dccb3aeca491_3987dd4a1f tabindex=-1></div><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class="button btn bg-main-600 hover:bg-main-400 shadow w-full"></div><p id=mce-error-response style=display:none class="text-center mt-2 opacity-50 text-main-200">There was a problem, please try again.</p><p id=mce-success-response style=display:none class="text-center mt-2 opacity-50 text-main-200">Thanks mate, won't let ya down.</p></form></div></div></div><div class="card_layer card_effect card_soft_glare" style=pointer-events:none></div></div></div></div></div></div></div><script language=javascript type=text/javascript src=https://cosmiccoding.com.au/js/main.min.11673d10a962fb5205229607e62ea1d23424d35dad33db7bfe2a09a63d5409fa.js></script>
<script async defer src="https://www.googletagmanager.com/gtag/js?id=G-GRX6QE03YR"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GRX6QE03YR")</script></div></body></html>